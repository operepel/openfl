{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis notebook tests model and optimizer state save and restore from\\none model instance to another, by inspecting the state using\\nmodel.state_dict() for model state and model.optimizer.state_dict()\\nfor optimizer. This is an automated single test that runs a test over\\na number of model and optimizer types.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This notebook tests model and optimizer state save and restore from\n",
    "one model instance to another, by inspecting the state using\n",
    "model.state_dict() for model state and model.optimizer.state_dict()\n",
    "for optimizer. This is an automated single test that runs a test over\n",
    "a number of model and optimizer types.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here set the gpu to one that is not ocupied\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe this is how we can test later, for now I am rewriting code below with the following changes\n",
    "# No shuffle on train and val\n",
    "# imports rewritten\n",
    "\n",
    "\n",
    "\n",
    "# from tfedlrn.collaborator.pytorchmodels.pytorch2dunet import PyTorch2DUNet\n",
    "# from tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn import PyTorchMNISTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing my own data pipeline initializer in order to enforce reproducibility by\n",
    "# selecting only one batch for training.\n",
    "\n",
    "from tfedlrn.datasets import load_dataset\n",
    "from tfedlrn.collaborator.pytorchmodels.pytorchflutils import pt_create_loader\n",
    "\n",
    "\n",
    "def init_data_pipelines_no_shuffle(model_type):\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    if model_type == PyTorchMNISTCNN:\n",
    "        \n",
    "        X_train, y_train, X_val, y_val = load_dataset('mnist')\n",
    "        X_train = X_train.reshape([-1, 1, 28, 28])\n",
    "        X_val = X_val.reshape([-1, 1, 28, 28])\n",
    "        \n",
    "        # Here is the key reason for implementing this myself.\n",
    "        # Reduce to producing only one batch for training.\n",
    "        X_train, y_train = X_train[:batch_size], y_train[:batch_size]\n",
    "\n",
    "        train_loader = pt_create_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = pt_create_loader(X_val, y_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        \n",
    "    elif model_type == PyTorch2DUNet:\n",
    "        \n",
    "        data_by_institution = [load_dataset('BraTS17_institution',\n",
    "                                                institution=i,\n",
    "                                                channels_first=True) for i in range(10)]\n",
    "        data_by_type = zip(*data_by_institution)\n",
    "        data_by_type = [np.concatenate(d) for d in data_by_type]\n",
    "        X_train, y_train, X_val, y_val = data_by_type\n",
    "        \n",
    "        # Here is the key reason for implementing this myself.\n",
    "        # Reduce to producing only one batch for training.\n",
    "        X_train, y_train = X_train[:batch_size], y_train[:batch_size]\n",
    "        \n",
    "        # Also reduce val loader for unet data so as to not take too long for validation\n",
    "        X_val, y_val = X_val[:batch_size], y_val[:batch_size]\n",
    "\n",
    "        train_loader = pt_create_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = pt_create_loader(X_val, y_val, batch_size=batch_size, shuffle=True)         \n",
    "         \n",
    "    else:\n",
    "        raise ValueError('This model type not supported.')\n",
    "               \n",
    "    return train_loader, val_loader\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn import PyTorchMNISTCNN\n",
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet import PyTorch2DUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(device, lr, model_type, optimizer_type, \n",
    "                     no_momentum=False):\n",
    "    train_loader, val_loader = init_data_pipelines_no_shuffle(model_type)\n",
    "    if model_type == PyTorchMNISTCNN:\n",
    "        cnn = PyTorchMNISTCNN(device=device, train_loader = train_loader, \n",
    "                              val_loader = val_loader)\n",
    "    else:\n",
    "        cnn = model_type(device=device, train_loader = train_loader, \n",
    "                         val_loader = val_loader, optimizer=optimizer_type)\n",
    "    # modifying the learning rate to make a more substantial change when training\n",
    "    # only on one batch, so as to detect after such training that the \n",
    "    # model was not restored correctly\n",
    "    for group_idx, group in enumerate(cnn.optimizer.__dict__['param_groups']):\n",
    "        cnn.optimizer.__dict__['param_groups'][group_idx]['lr'] = lr\n",
    "    cnn.optimizer.__dict__['defaults']['lr'] = lr\n",
    "    \n",
    "    # modifying the momentum so as to test SGD with no state needed\n",
    "    if no_momentum:\n",
    "        for group_idx, group in enumerate(cnn.optimizer.__dict__['param_groups']):\n",
    "            cnn.optimizer.__dict__['param_groups'][group_idx]['momentum'] = 0.0\n",
    "        cnn.optimizer.__dict__['defaults']['momentum'] = 0.0\n",
    "    \n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_of_weights_and_biases(cnn_1, cnn_2):\n",
    "    s_1 = cnn_1.state_dict()\n",
    "    s_2 = cnn_2.state_dict()\n",
    "    \n",
    "    bool_over_layers = []\n",
    "    for key in s_1:\n",
    "        bool_over_layers.append(bool(torch.all(torch.eq(s_1[key], s_2[key]))))\n",
    "        \n",
    "    return np.all(bool_over_layers)\n",
    "\n",
    "\n",
    "def equality_of_optimizer_state(cnn_1, cnn_2):\n",
    "    os_1 = cnn_1.optimizer.state_dict()['state']\n",
    "    os_2 = cnn_2.optimizer.state_dict()['state']\n",
    "    \n",
    "    key_groups_1 = [group['params'] for \n",
    "             group in cnn_1.optimizer.state_dict()['param_groups']]\n",
    "    key_groups_2 = [group['params'] for \n",
    "             group in cnn_2.optimizer.state_dict()['param_groups']]\n",
    "    bool_over_groups = []\n",
    "    for key_group_1, key_group_2 in zip(key_groups_1, key_groups_2):\n",
    "        for key_1, key_2 in zip(key_group_1, key_group_2):\n",
    "            subdict_1 = os_1[key_1]\n",
    "            subdict_2 = os_2[key_2]\n",
    "            for subkey in subdict_1:\n",
    "                if subkey == 'step':\n",
    "                    eq = subdict_1[subkey] == subdict_2[subkey]\n",
    "                else:\n",
    "                    tensor_1 = subdict_1[subkey]\n",
    "                    tensor_2 = subdict_2[subkey]\n",
    "                    eq = bool(torch.all(torch.eq(tensor_1, tensor_2)))\n",
    "                bool_over_groups.append(eq)\n",
    "    return np.all(bool_over_groups)\n",
    "\n",
    "\n",
    "def equality_of_models(cnn_1, cnn_2, no_momentum):\n",
    "    if no_momentum:\n",
    "        return equality_of_weights_and_biases(cnn_1, cnn_2)  \n",
    "    else:\n",
    "        return np.all([equality_of_weights_and_biases(cnn_1, cnn_2), \n",
    "                       equality_of_optimizer_state(cnn_1, cnn_2)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_test():\n",
    "    \n",
    "    devices = [torch.device(\"cpu\"), torch.device(\"cuda\")]\n",
    "    \n",
    "    example_kwargs = [{'model_type': PyTorchMNISTCNN, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorchMNISTCNN, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': True}, \n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'RMSprop', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'Adam', \n",
    "                       'no_momentum': False}]\n",
    "    \n",
    "    answers = []\n",
    "                     \n",
    "    for device in devices:\n",
    "        \n",
    "        for example_kwarg in example_kwargs:\n",
    "            no_momentum = example_kwarg['no_momentum']\n",
    "            cnn_1 = initialize_model(device=device, lr=0.01, **example_kwarg)\n",
    "            cnn_2 = initialize_model(device=device, lr=0.01, **example_kwarg)\n",
    "            \n",
    "            cnn_1.train_epoch()\n",
    "            cnn_2.train_epoch()\n",
    "            \n",
    "            # See that models are not equal.\n",
    "            should_be_false = equality_of_models(cnn_1, cnn_2, no_momentum)\n",
    "            \n",
    "            model_weights_1 = cnn_1.get_tensor_dict()\n",
    "            cnn_2.set_tensor_dict(model_weights_1)\n",
    "            \n",
    "            # See that models are now equal.\n",
    "            should_be_true = equality_of_models(cnn_1, cnn_2, no_momentum)\n",
    "            \n",
    "            success = should_be_true and not should_be_false\n",
    "            \n",
    "            answers.append(success)\n",
    "            \n",
    "            print(\"Config: {}, {}\".format(device, example_kwarg))\n",
    "            print(\"Succesful?: {}\\n\".format(success))\n",
    "    print(\"\\n\\nWas the whole test succesfull? {}\".format(np.all(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: cpu, {'optimizer_type': 'SGD', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cpu, {'optimizer_type': 'SGD', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cpu, {'optimizer_type': 'SGD', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cpu, {'optimizer_type': 'SGD', 'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cpu, {'optimizer_type': 'RMSprop', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cpu, {'optimizer_type': 'Adam', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cuda, {'optimizer_type': 'SGD', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cuda, {'optimizer_type': 'SGD', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cuda, {'optimizer_type': 'SGD', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cuda, {'optimizer_type': 'SGD', 'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cuda, {'optimizer_type': 'RMSprop', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "Config: cuda, {'optimizer_type': 'Adam', 'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>}\n",
      "Succesful?: True\n",
      "\n",
      "\n",
      "\n",
      "Was the whole test succesfull? True\n"
     ]
    }
   ],
   "source": [
    "full_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlearn",
   "language": "python",
   "name": "tfedlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
