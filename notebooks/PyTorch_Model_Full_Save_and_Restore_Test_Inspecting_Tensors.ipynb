{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook tests model and optimizer state save and restore from\n",
    "one model instance to another, by inspecting the state using\n",
    "model.state_dict() for model state and model.optimizer.state_dict()\n",
    "for optimizer. This is an automated single test that runs a test over\n",
    "a number of model and optimizer types.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe this is how we can test later, for now I am rewriting code below with the following changes\n",
    "# No shuffle on train and val\n",
    "# imports rewritten\n",
    "\n",
    "\n",
    "\n",
    "# from tfedlrn.collaborator.pytorchmodels.pytorch2dunet import PyTorch2DUNet\n",
    "# from tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn import PyTorchMNISTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing my own data pipeline initializer in order to enforce reproducibility by\n",
    "# selecting only one batch for training.\n",
    "\n",
    "from tfedlrn.datasets import load_dataset\n",
    "from tfedlrn.collaborator.pytorchmodels.pytorchflutils import pt_create_loader\n",
    "\n",
    "\n",
    "def init_data_pipelines_no_shuffle(model_type):\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    if model_type == PyTorchMNISTCNN:\n",
    "        \n",
    "        X_train, y_train, X_val, y_val = load_dataset('mnist')\n",
    "        X_train = X_train.reshape([-1, 1, 28, 28])\n",
    "        X_val = X_val.reshape([-1, 1, 28, 28])\n",
    "        \n",
    "        # Here is the key reason for implementing this myself.\n",
    "        # Reduce to producing only one batch for training.\n",
    "        X_train, y_train = X_train[:batch_size], y_train[:batch_size]\n",
    "\n",
    "        train_loader = pt_create_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = pt_create_loader(X_val, y_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        \n",
    "    elif model_type == PyTorch2DUNet:\n",
    "        \n",
    "        data_by_institution = [load_dataset('BraTS17_institution',\n",
    "                                                institution=i,\n",
    "                                                channels_first=True) for i in range(10)]\n",
    "        data_by_type = zip(*data_by_institution)\n",
    "        data_by_type = [np.concatenate(d) for d in data_by_type]\n",
    "        X_train, y_train, X_val, y_val = data_by_type\n",
    "        \n",
    "        # Here is the key reason for implementing this myself.\n",
    "        # Reduce to producing only one batch for training.\n",
    "        X_train, y_train = X_train[:batch_size], y_train[:batch_size]\n",
    "        \n",
    "        # Also reduce val loader for unet data so as to not take too long for validation\n",
    "        X_val, y_val = X_val[:batch_size], y_val[:batch_size]\n",
    "\n",
    "        train_loader = pt_create_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = pt_create_loader(X_val, y_val, batch_size=batch_size, shuffle=True)         \n",
    "         \n",
    "    else:\n",
    "        raise ValueError('This model type not supported.')\n",
    "               \n",
    "    return train_loader, val_loader\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn import PyTorchMNISTCNN\n",
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet import PyTorch2DUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(device, lr, model_type, optimizer_type, \n",
    "                     no_momentum=False):\n",
    "    train_loader, val_loader = init_data_pipelines_no_shuffle(model_type)\n",
    "    if model_type == PyTorchMNISTCNN:\n",
    "        cnn = PyTorchMNISTCNN(device=device, train_loader = train_loader, \n",
    "                              val_loader = val_loader)\n",
    "    else:\n",
    "        cnn = model_type(device=device, train_loader = train_loader, \n",
    "                         val_loader = val_loader, optimizer=optimizer_type)\n",
    "    # modifying the learning rate to make a more substantial change when training\n",
    "    # only on one batch, so as to detect after such training that the \n",
    "    # model was not restored correctly\n",
    "    for group_idx, group in enumerate(cnn.optimizer.__dict__['param_groups']):\n",
    "        cnn.optimizer.__dict__['param_groups'][group_idx]['lr'] = lr\n",
    "    cnn.optimizer.__dict__['defaults']['lr'] = lr\n",
    "    \n",
    "    # modifying the momentum so as to test SGD with no state needed\n",
    "    if no_momentum:\n",
    "        for group_idx, group in enumerate(cnn.optimizer.__dict__['param_groups']):\n",
    "            cnn.optimizer.__dict__['param_groups'][group_idx]['momentum'] = 0.0\n",
    "        cnn.optimizer.__dict__['defaults']['momentum'] = 0.0\n",
    "    \n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equality_of_weights_and_biases(cnn_1, cnn_2):\n",
    "    s_1 = cnn_1.state_dict()\n",
    "    s_2 = cnn_2.state_dict()\n",
    "    \n",
    "    bool_over_layers = []\n",
    "    for key in s_1:\n",
    "        bool_over_layers.append(bool(torch.all(torch.eq(s_1[key], s_2[key]))))\n",
    "        \n",
    "    return np.all(bool_over_layers)\n",
    "\n",
    "\n",
    "def equality_of_optimizer_state(cnn_1, cnn_2):\n",
    "    os_1 = cnn_1.optimizer.state_dict()['state']\n",
    "    os_2 = cnn_2.optimizer.state_dict()['state']\n",
    "    \n",
    "    key_groups_1 = [group['params'] for \n",
    "             group in cnn_1.optimizer.state_dict()['param_groups']]\n",
    "    key_groups_2 = [group['params'] for \n",
    "             group in cnn_2.optimizer.state_dict()['param_groups']]\n",
    "    bool_over_groups = []\n",
    "    for key_group_1, key_group_2 in zip(key_groups_1, key_groups_2):\n",
    "        for key_1, key_2 in zip(key_group_1, key_group_2):\n",
    "            subdict_1 = os_1[key_1]\n",
    "            subdict_2 = os_2[key_2]\n",
    "            for subkey in subdict_1:\n",
    "                if subkey == 'step':\n",
    "                    eq = subdict_1[subkey] == subdict_2[subkey]\n",
    "                else:\n",
    "                    tensor_1 = subdict_1[subkey]\n",
    "                    tensor_2 = subdict_2[subkey]\n",
    "                    eq = bool(torch.all(torch.eq(tensor_1, tensor_2)))\n",
    "                bool_over_groups.append(eq)\n",
    "    return np.all(bool_over_groups)\n",
    "\n",
    "\n",
    "def equality_of_models(cnn_1, cnn_2, no_momentum):\n",
    "    if no_momentum:\n",
    "        return equality_of_weights_and_biases(cnn_1, cnn_2)  \n",
    "    else:\n",
    "        return np.all([equality_of_weights_and_biases(cnn_1, cnn_2), \n",
    "                       equality_of_optimizer_state(cnn_1, cnn_2)])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_test():\n",
    "    \n",
    "    devices = [torch.device(\"cpu\"), torch.device(\"cuda\")]\n",
    "    \n",
    "    example_kwargs = [{'model_type': PyTorchMNISTCNN, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorchMNISTCNN, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'SGD', \n",
    "                       'no_momentum': True}, \n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'RMSprop', \n",
    "                       'no_momentum': False},\n",
    "                       {'model_type': PyTorch2DUNet, \n",
    "                       'optimizer_type': 'Adam', \n",
    "                       'no_momentum': False}]\n",
    "    \n",
    "    answers = []\n",
    "                     \n",
    "    for device in devices:\n",
    "        \n",
    "        for example_kwarg in example_kwargs:\n",
    "            print(example_kwarg)\n",
    "            no_momentum = example_kwarg['no_momentum']\n",
    "            cnn_1 = initialize_model(device=device, lr=0.01, **example_kwarg)\n",
    "            cnn_2 = initialize_model(device=device, lr=0.01, **example_kwarg)\n",
    "            \n",
    "            cnn_1.train_epoch()\n",
    "            cnn_2.train_epoch()\n",
    "            \n",
    "            # See that models are not equal.\n",
    "            should_be_false = equality_of_models(cnn_1, cnn_2, no_momentum)\n",
    "            \n",
    "            model_weights_1 = cnn_1.get_tensor_dict()\n",
    "            cnn_2.set_tensor_dict(model_weights_1)\n",
    "            \n",
    "            # See that models are now equal.\n",
    "            should_be_true = equality_of_models(cnn_1, cnn_2, no_momentum)\n",
    "            \n",
    "            success = should_be_true and not should_be_false\n",
    "            \n",
    "            answers.append(success)\n",
    "            \n",
    "            print(\"Config: {}\".format(example_kwargs))\n",
    "            print(\"Succesful?: {}\\n\".format(success))\n",
    "    print(\"\\n\\nWas the whole test succesfull? {}\".format(np.all(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}\n",
      "Config: [{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}]\n",
      "Succesful?: True\n",
      "\n",
      "{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}\n",
      "Config: [{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}]\n",
      "Succesful?: True\n",
      "\n",
      "{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}\n",
      "Config: [{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}]\n",
      "Succesful?: True\n",
      "\n",
      "{'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}\n",
      "Config: [{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}]\n",
      "Succesful?: True\n",
      "\n",
      "{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}\n",
      "Config: [{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}]\n",
      "Succesful?: True\n",
      "\n",
      "{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}\n",
      "Config: [{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': True, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'SGD'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'RMSprop'}, {'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorch2dunet.PyTorch2DUNet'>, 'optimizer_type': 'Adam'}]\n",
      "Succesful?: True\n",
      "\n",
      "{'no_momentum': False, 'model_type': <class 'tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn.PyTorchMNISTCNN'>, 'optimizer_type': 'SGD'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-707c494a5243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-ef81c7ad25d4>\u001b[0m in \u001b[0;36mfull_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_kwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mno_momentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample_kwarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'no_momentum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mcnn_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexample_kwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mcnn_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mexample_kwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-c51728497453>\u001b[0m in \u001b[0;36minitialize_model\u001b[0;34m(device, lr, model_type, optimizer_type, no_momentum)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPyTorchMNISTCNN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         cnn = PyTorchMNISTCNN(device=device, train_loader = train_loader, \n\u001b[0;32m----> 6\u001b[0;31m                               val_loader = val_loader)\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         cnn = model_type(device=device, train_loader = train_loader, \n",
      "\u001b[0;32m~/repositories/spr_secure_intelligence-trusted_federated_learning/tfedlrn/collaborator/pytorchmodels/pytorchmnistcnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_data_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/repositories/spr_secure_intelligence-trusted_federated_learning/tfedlrn/collaborator/pytorchmodels/pytorchmnistcnn.py\u001b[0m in \u001b[0;36minit_network\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/spr_secure_intelligence-trusted_federated_-aNwh6wSd/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/spr_secure_intelligence-trusted_federated_-aNwh6wSd/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/spr_secure_intelligence-trusted_federated_-aNwh6wSd/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/spr_secure_intelligence-trusted_federated_-aNwh6wSd/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/spr_secure_intelligence-trusted_federated_-aNwh6wSd/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m         raise RuntimeError(\n\u001b[1;32m    161\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/spr_secure_intelligence-trusted_federated_-aNwh6wSd/lib/python3.5/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "full_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here set what type of model, dataset, and optimizer you want\n",
    "# (for mnist, no optimizer is needed). Testing using the device as\n",
    "# GPU and CPU should be performed, as well as testing with all optimizer\n",
    "# options, including SGD with momentum=0.0 in order to see that no\n",
    "# required state for the optimizer is handled correctly.\n",
    "\n",
    "# model_type = PyTorchMNISTCNN\n",
    "\n",
    "\n",
    "model_type = PyTorch2DUNet\n",
    "\n",
    "\n",
    "unet_optimizer_type = 'SGD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############         EXPLORING SAVING AND RESTORING OPTIMIZER and MODEL          ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = initialize_model(device=device, model_type=model_type, \n",
    "                       unet_optimizer_type=unet_optimizer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training once to populate the momentum buffers\n",
    "# also testing the extent to which validation is reproducible for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5348387"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate() - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# testing restoring model and optimizer, should result in training to the same validation ##\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003709124866873026"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_val = cnn.validate()\n",
    "initial_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_weights = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for some more, then see that model is different now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005393"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.423956852406263e-06"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure validation has changed significantly now relative to the difference in repeated validation\n",
    "after_train_val = cnn.validate()\n",
    "after_train_val - initial_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk as well as initial_val and after_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filenames = ['saved_model.pkl', 'initial_val.pkl', 'after_train_val.pkl']\n",
    "objects = [model_weights, initial_val, after_train_val]\n",
    "for ob, filename in zip(objects, filenames):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(ob, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\\/ exploration code here \\/---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here exploring how to modify the learning rate using the optimizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.optimizer.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here that the param_groups contain lr info\n",
    "print(cnn.optimizer.__dict__['param_groups'][0].keys())\n",
    "print(cnn.optimizer.__dict__['param_groups'][0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here that the defaults also contain lr \n",
    "# info (this is used by us when restoring optimizer state).\n",
    "print(cnn.optimizer.__dict__['param_groups'][0].keys())\n",
    "print(cnn.optimizer.__dict__['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here (by exploring first state key only) that lr info does not lie below the 'state' key \n",
    "first_state_key = list(cnn.optimizer.__dict__['state'].keys())[0]\n",
    "cnn.optimizer.__dict__['state'][first_state_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring how np.float and torch.FloatTensor are indeed compatible.\n",
    "# In fact, the tensors below point to the same memory store, though they print differently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([4.00343, 5.00676]).astype(np.float32)\n",
    "tensor = torch.Tensor(array).to(device)\n",
    "print(\"array data,tensor data, and datatype: {}, {}, {}\"\n",
    "      .format(array, tensor, tensor.type()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([4.00340, 5.00676]).astype(np.float32)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(\"array data,tensor data, and datatype: {}, {}, {}\"\n",
    "      .format(array, tensor, tensor.type()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array += 1.00004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ /\\ exploration code here /\\ ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore saved model\n",
    "cnn.set_tensor_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see validation is close to previously observed for saved model\n",
    "initial_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if grabbing the full state again, it gives the same thing as we had saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_2 = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_array = np.array([])\n",
    "for key in model_weights:\n",
    "    if key.startswith('__opt_'):\n",
    "        for inner_key in model_weights[key]:\n",
    "            np.append(bool_array, model_weights[key][inner_key] == model_weights_2[key][inner_key])\n",
    "    else:\n",
    "        np.append(bool_array, [np.all(model_weights[key] == model_weights_2[key])])\n",
    "np.all(bool_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train again and see you get back to the place you did before after running 'train_partial_epoch' once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005393"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9103830456733704e-11"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_train_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_train_val - cnn.validate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----now test that restoring can happen across processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######                         !!!!!!!!!!!!!!!!  RESTART KERNEL HERE !!!!!!!!!!!                 #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######         (then run the top cells of this workbook up to device intialization)            ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Then return to this point and run cells below ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate model and train a bit, then restore model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = initialize_model(device=device, model_type=model_type, \n",
    "                       unet_optimizer_type=unet_optimizer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model weights and validation values from disk BUT NOT RESTORING YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['saved_model.pkl', 'initial_val.pkl', 'after_train_val.pkl']\n",
    "object_names = ['model_weights', 'initial_val', 'after_train_val']\n",
    "for object_name, filename in zip(object_names, filenames):\n",
    "    with open(filename, 'rb') as file:\n",
    "        vars()[object_name] = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.514906322583556e-06, -9.094947017729282e-08)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if valiation is significantly different from the ones before\n",
    "this_val = cnn.validate()\n",
    "initial_val - this_val,  after_train_val - this_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore model to saved values\n",
    "cnn.set_tensor_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9103830456733704e-11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see validation is close to previously observed for saved model\n",
    "initial_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if grabbing the full state again, it gives the same thing as we had saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_2 = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_array = np.array([])\n",
    "for key in model_weights:\n",
    "    if key.startswith('__opt_'):\n",
    "        for inner_key in model_weights[key]:\n",
    "            np.append(bool_array, model_weights[key][inner_key] == model_weights_2[key][inner_key])\n",
    "    else:\n",
    "        np.append(bool_array, [np.all(model_weights[key] == model_weights_2[key])])\n",
    "np.all(bool_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005393"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now train to get a new validation, and see that it matches what we had after training once before\n",
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9103830456733704e-11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "after_train_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlearn",
   "language": "python",
   "name": "tfedlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
