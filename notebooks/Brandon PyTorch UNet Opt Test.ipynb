{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes work from Pytorch MNIST and UNet Dev.ipynb, takes the UNet portion only, and makes \n",
    "# training and validation repeatable in order\n",
    "# to test a method for saving and setting optimizer state (momentum, etc.) that remains consistent\n",
    "# even when the restoring is done after restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the cells below (up to ######) when restarting kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class FLModel(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_tensor_dict(self):\n",
    "        \"\"\"Returns all parameters for aggregation, including optimizer parameters, if appropriate\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def set_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"Returns all parameters for aggregation, including optimizer parameters, if appropriate\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def train_epoch(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_training_data_size(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def validate(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_validation_data_size(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import socket\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def _get_dataset_func_map():\n",
    "    return {\n",
    "        'mnist': load_mnist,\n",
    "#         'fashion-mnist': load_fashion_mnist,\n",
    "#         'pubfig83': load_pubfig83,\n",
    "#         'cifar10': load_cifar10,\n",
    "#         'cifar20': load_cifar20,\n",
    "#         'cifar100': load_cifar100,\n",
    "#         'bsm': load_bsm,\n",
    "#         'BraTS17': load_BraTS17,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_dataset_list():\n",
    "    return list(_get_dataset_func_map().keys())\n",
    "\n",
    "\n",
    "def load_dataset(dataset, **kwargs):\n",
    "    if dataset not in get_dataset_list():\n",
    "        raise ValueError(\"Dataset {} not in list of datasets {get_dataset_list()}\".format(dataset))\n",
    "    return _get_dataset_func_map()[dataset](**kwargs)\n",
    "\n",
    "\n",
    "def _get_dataset_dir(server='edwardsb-Z270x-UD5'):\n",
    "    if server is None:\n",
    "        server = socket.gethostname()\n",
    "    server_to_path = {'spr-gpu01': os.path.join('/', 'raid', 'datasets'),\n",
    "                      'edwardsb-Z270X-UD5': os.path.join('/', 'data'),\n",
    "                      'msheller-ubuntu': os.path.join('/', 'home', 'msheller', 'datasets')}\n",
    "    return server_to_path[server]\n",
    "\n",
    "\n",
    "def _unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        d = pickle.load(fo, encoding='bytes')\n",
    "    return d\n",
    "\n",
    "\n",
    "def _read_mnist(path, **kwargs):\n",
    "    X_train, y_train = _read_mnist_kind(path, kind='train', **kwargs)\n",
    "    X_test, y_test = _read_mnist_kind(path, kind='t10k', **kwargs)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# from https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "def _read_mnist_kind(path, kind='train', one_hot=True, **kwargs):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    images = images.astype(float) / 255\n",
    "    if one_hot:\n",
    "        labels = _one_hot(labels.astype(np.int), 10)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_mnist(**kwargs):\n",
    "    path = os.path.join(_get_dataset_dir(), 'mnist', 'input_data')\n",
    "    return _read_mnist(path, **kwargs)\n",
    "\n",
    "\n",
    "def load_fashion_mnist(**kwargs):\n",
    "    path = os.path.join(_get_dataset_dir(), 'fashion-mnist')\n",
    "    return _read_mnist(path, **kwargs)\n",
    "\n",
    "\n",
    "def _one_hot(y, n):\n",
    "    return np.eye(n)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PyTorchFLModel(FLModel, nn.Module):\n",
    "    \"\"\"WIP code. Goal is to simplify porting a model to this framework.\n",
    "    Currently, this creates a placeholder and assign op for every variable, which grows the graph considerably.\n",
    "    Also, the abstraction for the tf.session isn't ideal yet.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # calls nn.Module init\n",
    "        super(PyTorchFLModel, self).__init__()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_optimizer(self):\n",
    "        pass\n",
    "\n",
    "    def get_optimizer_tensors(self):\n",
    "        optimizer = self.get_optimizer()\n",
    "\n",
    "        tensor_dict = {}\n",
    "\n",
    "        # NOTE: this gave inconsistent orderings across collaborators, so does not work\n",
    "        # state = optimizer.state_dict()['state']\n",
    "\n",
    "        # # FIXME: this is really fragile. Need to understand what could change here\n",
    "        # for i, sk in enumerate(state.keys()):\n",
    "        #     if isinstance(state[sk], dict):\n",
    "        #         for k, v in state[sk].items():\n",
    "        #             if isinstance(v, torch.Tensor):\n",
    "        #                 tensor_dict['{}_{}'.format(i, k)] = v.cpu().numpy()\n",
    "\n",
    "        # FIXME: not clear that this works consistently across optimizers\n",
    "        # FIXME: hard-coded naming convention sucks and could absolutely break\n",
    "        i = 0\n",
    "        for group in optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                tensor_dict['__opt_{}'.format(i)] = p.detach().cpu().numpy()\n",
    "                i += 1\n",
    "\n",
    "        return tensor_dict\n",
    "                    \n",
    "    def set_optimizer_tensors(self, tensor_dict):\n",
    "        optimizer = self.get_optimizer()\n",
    "\n",
    "        # NOTE: the state dict ordering wasn't consistent. We'd like to use load_state_dict rather than\n",
    "        # directly setting the tensors, if possible, but it's not clear that we can\n",
    "#         state = optimizer.state_dict()\n",
    "\n",
    "#         # FIXME: this is really fragile. Need to understand what could change here\n",
    "#         for i, sk in enumerate(state['state'].keys()):\n",
    "#             if isinstance(state['state'][sk], dict):\n",
    "#                 for k, v in state['state'][sk].items():\n",
    "#                     if isinstance(v, torch.Tensor):\n",
    "#                         key = '{}_{}'.format(i, k)\n",
    "                        \n",
    "#                         if key not in tensor_dict:\n",
    "#                             raise ValueError('{} not in keys: {}'.format(key, list(tensor_dict.keys())))\n",
    "                        \n",
    "#                         state['state'][sk][k] = torch.Tensor(tensor_dict[key]).to(v.device)\n",
    "#         optimizer.load_state_dict(state)\n",
    "        \n",
    "        # FIXME: not clear that this works consistently across optimizers\n",
    "        # FIXME: hard-coded naming convention sucks and could absolutely break\n",
    "        i = 0\n",
    "        for group in optimizer.param_groups:\n",
    "            for idx, p in enumerate(group['params']):\n",
    "                old = group['params'][idx]\n",
    "                new = torch.Tensor(tensor_dict['__opt_{}'.format(i)]).to(old.device)\n",
    "\n",
    "    def get_tensor_dict(self):\n",
    "        # FIXME: should we use self.parameters()??? Unclear if load_state_dict() is better or simple assignment is better\n",
    "        # for now, state dict gives us names, which is good\n",
    "\n",
    "        # FIXME: do both and sanity check each time?\n",
    "\n",
    "        # FIXME: can this have values other than the tensors????\n",
    "        state = self.state_dict()\n",
    "        for k, v in state.items():\n",
    "            state[k] = v.cpu().numpy() # get as a numpy array\n",
    "        return {**state, **self.get_optimizer_tensors()}\n",
    "\n",
    "    def set_tensor_dict(self, tensor_dict):\n",
    "        # FIXME: should we use self.parameters()??? Unclear if load_state_dict() is better or simple assignment is better\n",
    "        # for now, state dict gives us names, which is good\n",
    "        \n",
    "        # FIXME: do both and sanity check each time?\n",
    "\n",
    "        # get the model state so that we can determine the correct tensor values/device placements\n",
    "        model_state = self.state_dict()\n",
    "\n",
    "        new_state = {}\n",
    "        for k, v in model_state.items():\n",
    "            new_state[k] = torch.Tensor(tensor_dict[k]).to(v.device)\n",
    "\n",
    "        # set model state\n",
    "        self.load_state_dict(new_state)\n",
    "\n",
    "        # next we have the optimizer state\n",
    "        self.set_optimizer_tensors(tensor_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PyTorchMNISTCNN(PyTorchFLModel):\n",
    "\n",
    "    def __init__(self, device, train_loader=None, val_loader=None):\n",
    "        super(PyTorchMNISTCNN, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.init_data_pipeline(train_loader, val_loader)\n",
    "        self.init_network(device)\n",
    "        self.init_optimizer()\n",
    "\n",
    "    def create_loader(self, X, y, **kwargs):\n",
    "        tX = torch.stack([torch.Tensor(i) for i in X])\n",
    "        ty = torch.stack([torch.Tensor(i) for i in y])\n",
    "        return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tX, ty), **kwargs)\n",
    "\n",
    "    def init_data_pipeline(self, train_loader, val_loader):\n",
    "        if train_loader is None or val_loader is None:\n",
    "            X_train, y_train, X_val, y_val = load_dataset('mnist')\n",
    "            X_train = X_train.reshape([-1, 1, 28, 28])\n",
    "            X_val = X_val.reshape([-1, 1, 28, 28])\n",
    "\n",
    "        if train_loader is None:\n",
    "            self.train_loader = self.create_loader(X_train, y_train, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            self.train_loader = train_loader\n",
    "\n",
    "        if val_loader is None:\n",
    "            self.val_loader = self.create_loader(X_val, y_val, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            self.val_loader = val_loader\n",
    "\n",
    "    def init_network(self, device):\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set to \"training\" mode\n",
    "        self.train()\n",
    "        \n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device, dtype=torch.int64)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self(data)\n",
    "            loss = F.cross_entropy(output, torch.max(target, 1)[1])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "        return np.mean(losses)\n",
    "\n",
    "    def get_training_data_size(self):\n",
    "        return len(self.train_loader.dataset)\n",
    "\n",
    "    def validate(self):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device, dtype=torch.int64)\n",
    "                output = self(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                target = torch.max(target, 1)[1]\n",
    "                # FIXME: there has to be a better way than exhaustive eq then diagonal\n",
    "                eq = pred.eq(target).diag().sum().cpu().numpy()\n",
    "                correct += eq\n",
    "\n",
    "        return correct / self.get_validation_data_size()\n",
    "\n",
    "    def get_validation_data_size(self):\n",
    "        return len(self.val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tfedlrn.datasets import load_dataset\n",
    "from tfedlrn.collaborator.pytorchflmodel import PyTorchFLModel\n",
    "\n",
    "\n",
    "def dice_coef(pred, target, smoothing=1.0):    \n",
    "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "    union = (pred + target).sum(dim=(1, 2, 3))\n",
    "    \n",
    "    return ((2 * intersection + smoothing) / (union + smoothing)).mean()\n",
    "\n",
    "\n",
    "def dice_coef_loss(pred, target, smoothing=1.0):    \n",
    "    intersection = (pred * target).sum(dim=(1, 2, 3))\n",
    "    union = (pred + target).sum(dim=(1, 2, 3))\n",
    "    \n",
    "    term1 = -torch.log(2 * intersection + smoothing)\n",
    "    term2 = torch.log(union + smoothing)\n",
    "    \n",
    "    return term1.mean() + term2.mean()\n",
    "\n",
    "\n",
    "class PyTorch2DUNet(PyTorchFLModel):\n",
    "\n",
    "    def __init__(self, device, train_loader=None, val_loader=None, optimizer='SGD'):\n",
    "        super(PyTorch2DUNet, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.init_data_pipeline(train_loader, val_loader)\n",
    "        self.init_network(device)\n",
    "        self.init_optimizer(optimizer)\n",
    "        \n",
    "    def create_loader(self, X, y, **kwargs):\n",
    "        tX = torch.stack([torch.Tensor(i) for i in X])\n",
    "        ty = torch.stack([torch.Tensor(i) for i in y])\n",
    "        return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tX, ty), **kwargs)\n",
    "\n",
    "    # FIXME: brats loading\n",
    "    def init_data_pipeline(self, train_loader, val_loader):\n",
    "        if train_loader is None or val_loader is None:\n",
    "            # load all the institutions\n",
    "            data_by_institution = [load_dataset('BraTS17_institution',\n",
    "                                                channels_first=True,\n",
    "                                                institution=i) for i in range(10)]\n",
    "            data_by_type = zip(*data_by_institution)\n",
    "            data_by_type = [np.concatenate(d) for d in data_by_type]\n",
    "            X_train, y_train, X_val, y_val = data_by_type\n",
    "\n",
    "        #TODO: Replace both shuffle=False below with shuffle=True, currently testing and so want reproducibility\n",
    "        if train_loader is None:\n",
    "            self.train_loader = self.create_loader(X_train, y_train, batch_size=64, shuffle=False)\n",
    "        else:\n",
    "            self.train_loader = train_loader\n",
    "\n",
    "        if val_loader is None:\n",
    "            self.val_loader = self.create_loader(X_val, y_val, batch_size=64, shuffle=False)\n",
    "        else:\n",
    "            self.val_loader = val_loader\n",
    "            \n",
    "    def init_network(self,\n",
    "                     device,\n",
    "                     initial_channels=1,\n",
    "                     depth_per_side=5,\n",
    "                     initial_filters=32):\n",
    "\n",
    "        f = initial_filters\n",
    "        \n",
    "        # store our depth for our forward function\n",
    "        self.depth_per_side = 5\n",
    "        \n",
    "        # parameter-less layers\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "                \n",
    "        # initial down layers\n",
    "        conv_down_a = [nn.Conv2d(initial_channels, f, 3, padding=1)]\n",
    "        conv_down_b = [nn.Conv2d(f, f, 3, padding=1)]\n",
    "                \n",
    "        # rest of the layers going down\n",
    "        for i in range(1, depth_per_side):\n",
    "            f *= 2\n",
    "            conv_down_a.append(nn.Conv2d(f // 2, f, 3, padding=1))\n",
    "            conv_down_b.append(nn.Conv2d(f, f, 3, padding=1))\n",
    "            \n",
    "        # going up, do all but the last layer\n",
    "        conv_up_a = []\n",
    "        conv_up_b = []\n",
    "        for _ in range(depth_per_side-1):\n",
    "            f //= 2\n",
    "            # triple input channels due to skip connections\n",
    "            conv_up_a.append(nn.Conv2d(f*3, f, 3, padding=1))\n",
    "            conv_up_b.append(nn.Conv2d(f, f, 3, padding=1))\n",
    "            \n",
    "        # do the last layer\n",
    "        self.conv_out = nn.Conv2d(f, 1, 1, padding=0)\n",
    "        \n",
    "        # all up/down layers need to to become fields of this object\n",
    "        for i, (a, b) in enumerate(zip(conv_down_a, conv_down_b)):\n",
    "            setattr(self, 'conv_down_{}a'.format(i+1), a)\n",
    "            setattr(self, 'conv_down_{}b'.format(i+1), b)\n",
    "            \n",
    "        # all up/down layers need to to become fields of this object\n",
    "        for i, (a, b) in enumerate(zip(conv_up_a, conv_up_b)):\n",
    "            setattr(self, 'conv_up_{}a'.format(i+1), a)\n",
    "            setattr(self, 'conv_up_{}b'.format(i+1), b)\n",
    "        \n",
    "        # send this to the device\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # gather up our up and down layer members for easier processing\n",
    "        conv_down_a = [getattr(self, 'conv_down_{}a'.format(i+1)) for i in range(self.depth_per_side)]\n",
    "        conv_down_b = [getattr(self, 'conv_down_{}b'.format(i+1)) for i in range(self.depth_per_side)]\n",
    "        conv_up_a = [getattr(self, 'conv_up_{}a'.format(i+1)) for i in range(self.depth_per_side - 1)]\n",
    "        conv_up_b = [getattr(self, 'conv_up_{}b'.format(i+1)) for i in range(self.depth_per_side - 1)]\n",
    "        \n",
    "        # we concatenate the outputs from the b layers\n",
    "        concat_me = []\n",
    "        pool = x\n",
    "\n",
    "        # going down, wire each pair and then pool except the last\n",
    "        for a, b in zip(conv_down_a, conv_down_b):\n",
    "            out_down = F.relu(b(F.relu(a(pool))))\n",
    "            # if not the last down b layer, pool it and add it to the concat list\n",
    "            if b != conv_down_b[-1]:\n",
    "                concat_me.append(out_down)\n",
    "                pool = self.maxpool(out_down) # feed the pool into the next layer\n",
    "        \n",
    "        # reverse the concat_me layers\n",
    "        concat_me = concat_me[::-1]\n",
    "\n",
    "        # we start going up with the b (not-pooled) from previous layer\n",
    "        in_up = out_down\n",
    "\n",
    "        # going up, we need to zip a, b and concat_me\n",
    "        for a, b, c in zip(conv_up_a, conv_up_b, concat_me):\n",
    "            up = torch.cat([self.upsample(in_up), c], dim=1)\n",
    "            in_up = F.relu(b(F.relu(a(up))))\n",
    "        \n",
    "        # finally, return the output\n",
    "        return torch.sigmoid(self.conv_out(in_up))\n",
    "\n",
    "    def init_optimizer(self, optimizer='SGD'):\n",
    "        if optimizer == 'SGD':\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr=1e-3, momentum=0.9)\n",
    "        elif optimizer == 'RMSprop':\n",
    "            self.optimizer = optim.RMSprop(self.parameters(), lr=1e-5, momentum=0.9)\n",
    "        elif optimizer == 'Adam':\n",
    "            self.optimizer = optim.Adam(self.parameters(), lr=1e-5)\n",
    "        else:\n",
    "            raise ValueError()\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set to \"training\" mode\n",
    "        self.train()\n",
    "        \n",
    "        losses = []\n",
    "\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            \n",
    "            # TODO: Remove below - storing cpu data to inspect below\n",
    "            cpu_data, cpu_target = data, target\n",
    "            \n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self(data)\n",
    "            loss = dice_coef_loss(output, target, smoothing=32.0)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "            #TODO: Remove below- just performing one batch of training now for testing below\n",
    "            info = \"Sum of batch is data: {}, target: {}\".format(np.sum(cpu_data.numpy(), axis=0), \n",
    "                                                                 np.sum(cpu_target.numpy(), axis=0))\n",
    "            break\n",
    "            \n",
    "        return np.mean(losses), info\n",
    "\n",
    "    def get_training_data_size(self):\n",
    "        return len(self.train_loader.dataset)\n",
    "\n",
    "    def validate(self):\n",
    "        self.eval()\n",
    "        dice = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            counter = 0\n",
    "            for data, target in self.val_loader:\n",
    "                samples = target.shape[0]\n",
    "                total_samples += samples\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self(data)\n",
    "                dice += dice_coef(output, target).cpu().numpy() * samples\n",
    "                counter += 1\n",
    "                if counter == 2:\n",
    "                    break\n",
    "        return dice / total_samples\n",
    "\n",
    "    def get_validation_data_size(self):\n",
    "        return len(self.val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### EXPLORING OPTIMIZER PARAMETERS (SAVING AND RESTORING) ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = PyTorch2DUNet(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing that the data used for training is reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.480192,\n",
       " 'Sum of batch is data: [[[-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  ...\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]]], target: [[[0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]]]')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.5863986,\n",
       " 'Sum of batch is data: [[[-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  ...\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]]], target: [[[0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]]]')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing that validation is reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034646598491235636"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034646598491235636"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn.optimizer.state_dict()['param_groups'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dampening': 0,\n",
       " 'lr': 0.001,\n",
       " 'momentum': 0.9,\n",
       " 'nesterov': False,\n",
       " 'params': [140698930495352,\n",
       "  140698930495424,\n",
       "  140698930492472,\n",
       "  140698930492544,\n",
       "  140698930492616,\n",
       "  140698930492688,\n",
       "  140698930492832,\n",
       "  140698930492904,\n",
       "  140698930492976,\n",
       "  140698930493048,\n",
       "  140698930493120,\n",
       "  140698930493192,\n",
       "  140698930493264,\n",
       "  140698930493336,\n",
       "  140698930493408,\n",
       "  140698930493480,\n",
       "  140698930493552,\n",
       "  140698930493624,\n",
       "  140698930493696,\n",
       "  140698930493768,\n",
       "  140698930493840,\n",
       "  140698930493912,\n",
       "  140698930493984,\n",
       "  140698930494056,\n",
       "  140698930494128,\n",
       "  140698930494200,\n",
       "  140698930494272,\n",
       "  140698930494344,\n",
       "  140698930494416,\n",
       "  140698930494488,\n",
       "  140698930494560,\n",
       "  140698930494632,\n",
       "  140698930494704,\n",
       "  140698930494776,\n",
       "  140698930494848,\n",
       "  140698930494920,\n",
       "  140698930494992,\n",
       "  140698930495064],\n",
       " 'weight_decay': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['param_groups'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note though the keys are the same, they are not in the same order\n",
    "# when saving and restoring, we will traverse in the order given by the list object to rely on python list ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([140698930495424, 140698930492544, 140698930493480, 140698930494416, 140698930493408, 140698930494920, 140698930493048, 140698930495064, 140698930492688, 140698930494272, 140698930493840, 140698930493624, 140698930494992, 140698930492976, 140698930493336, 140698930494632, 140698930492616, 140698930493984, 140698930493264, 140698930493912, 140698930492904, 140698930494056, 140698930493552, 140698930494200, 140698930493192, 140698930493768, 140698930494704, 140698930494344, 140698930494848, 140698930492832, 140698930493696, 140698930494488, 140698930492472, 140698930495352, 140698930494128, 140698930493120, 140698930494560, 140698930494776])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140698930495352,\n",
       " 140698930495424,\n",
       " 140698930492472,\n",
       " 140698930492544,\n",
       " 140698930492616,\n",
       " 140698930492688,\n",
       " 140698930492832,\n",
       " 140698930492904,\n",
       " 140698930492976,\n",
       " 140698930493048,\n",
       " 140698930493120,\n",
       " 140698930493192,\n",
       " 140698930493264,\n",
       " 140698930493336,\n",
       " 140698930493408,\n",
       " 140698930493480,\n",
       " 140698930493552,\n",
       " 140698930493624,\n",
       " 140698930493696,\n",
       " 140698930493768,\n",
       " 140698930493840,\n",
       " 140698930493912,\n",
       " 140698930493984,\n",
       " 140698930494056,\n",
       " 140698930494128,\n",
       " 140698930494200,\n",
       " 140698930494272,\n",
       " 140698930494344,\n",
       " 140698930494416,\n",
       " 140698930494488,\n",
       " 140698930494560,\n",
       " 140698930494632,\n",
       " 140698930494704,\n",
       " 140698930494776,\n",
       " 140698930494848,\n",
       " 140698930494920,\n",
       " 140698930494992,\n",
       " 140698930495064]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['param_groups'][0]['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 38 optimizer keys.\n"
     ]
    }
   ],
   "source": [
    "# getting the keys to be used for the dictionary: cnn.optimizer.state_dict()['state']\n",
    "optimizer_keys = []\n",
    "for group in cnn.optimizer.state_dict()['param_groups']:\n",
    "    for key in group['params']:\n",
    "        optimizer_keys.append(key)\n",
    "print(\"there are {} optimizer keys.\".format(len(optimizer_keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'momentum_buffer': tensor([[[[4.2651e-05]],\n",
       " \n",
       "          [[1.5496e-02]],\n",
       " \n",
       "          [[5.5317e-03]],\n",
       " \n",
       "          [[3.3534e-02]],\n",
       " \n",
       "          [[5.5599e-03]],\n",
       " \n",
       "          [[1.1801e-02]],\n",
       " \n",
       "          [[1.9776e-02]],\n",
       " \n",
       "          [[1.0708e-03]],\n",
       " \n",
       "          [[3.6289e-08]],\n",
       " \n",
       "          [[9.2248e-07]],\n",
       " \n",
       "          [[3.3608e-02]],\n",
       " \n",
       "          [[8.8546e-03]],\n",
       " \n",
       "          [[1.6957e-02]],\n",
       " \n",
       "          [[7.5179e-08]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[2.2632e-03]],\n",
       " \n",
       "          [[1.4548e-02]],\n",
       " \n",
       "          [[8.5252e-05]],\n",
       " \n",
       "          [[3.7501e-06]],\n",
       " \n",
       "          [[2.5499e-08]],\n",
       " \n",
       "          [[5.6561e-03]],\n",
       " \n",
       "          [[3.2854e-09]],\n",
       " \n",
       "          [[1.8336e-02]],\n",
       " \n",
       "          [[7.0124e-07]],\n",
       " \n",
       "          [[2.1024e-04]],\n",
       " \n",
       "          [[2.0376e-09]],\n",
       " \n",
       "          [[2.9095e-03]],\n",
       " \n",
       "          [[8.5573e-03]],\n",
       " \n",
       "          [[2.9018e-02]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[6.2537e-04]],\n",
       " \n",
       "          [[1.6738e-10]]]], device='cuda:0')}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer']),\n",
       " dict_keys(['momentum_buffer'])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing to see that 'momentum_buffer' is all that is there for this optimizer\n",
    "[cnn.optimizer.state_dict()['state'][key].keys() for key in cnn.optimizer.state_dict()['param_groups'][0]['params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the order of sizes of the momentum buffers when using 'optimizer_keys'\n",
    "# Note that you can run this over and over after restarting the kernel, but I perform\n",
    "# that test more sytematically at the end of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cnn.optimizer.state_dict()['state'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[0]]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[1]]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 3, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[2]]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[3]]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[4]]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[5]]['momentum_buffer'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing restoring model and optimizer, should result in training to the same validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034646598491235636"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save optimizer state\n",
    "optimizer_state = {}\n",
    "i = 0\n",
    "for group in cnn.optimizer.state_dict()['param_groups']:\n",
    "    for key in group['params']:\n",
    "        optimizer_state[i] = cnn.optimizer.state_dict()['state'][key]['momentum_buffer'].detach().cpu().numpy()\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_weights = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.5859056,\n",
       " 'Sum of batch is data: [[[-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  ...\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]]], target: [[[0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]]]')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03464584346511401"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see valiation is not the same now\n",
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore saved model\n",
    "cnn.set_tensor_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034646598491235636"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see validation is back to previously observed for saved model\n",
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now look at a piece of the optimizer state to see that it does not match what we  had saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'momentum_buffer': tensor([[[[1.4488e-02]],\n",
       " \n",
       "          [[9.3489e-06]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[3.2723e-02]],\n",
       " \n",
       "          [[2.8575e-02]],\n",
       " \n",
       "          [[1.8181e-04]],\n",
       " \n",
       "          [[3.0210e-02]],\n",
       " \n",
       "          [[4.8071e-05]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[8.3902e-04]],\n",
       " \n",
       "          [[8.1692e-05]],\n",
       " \n",
       "          [[5.9734e-02]],\n",
       " \n",
       "          [[6.2871e-02]],\n",
       " \n",
       "          [[5.2276e-02]],\n",
       " \n",
       "          [[3.1715e-02]],\n",
       " \n",
       "          [[5.3174e-02]],\n",
       " \n",
       "          [[7.0356e-02]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[9.3755e-05]],\n",
       " \n",
       "          [[1.5996e-02]],\n",
       " \n",
       "          [[8.5440e-04]],\n",
       " \n",
       "          [[7.3476e-02]],\n",
       " \n",
       "          [[9.3773e-04]],\n",
       " \n",
       "          [[5.3554e-02]],\n",
       " \n",
       "          [[3.4916e-02]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[4.1385e-03]],\n",
       " \n",
       "          [[1.3060e-02]],\n",
       " \n",
       "          [[3.6511e-02]],\n",
       " \n",
       "          [[1.0374e-06]],\n",
       " \n",
       "          [[2.2838e-05]],\n",
       " \n",
       "          [[5.2651e-03]]]], device='cuda:0')}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.01544615e-02]],\n",
       "\n",
       "        [[6.54031192e-06]],\n",
       "\n",
       "        [[0.00000000e+00]],\n",
       "\n",
       "        [[2.29606144e-02]],\n",
       "\n",
       "        [[2.00559720e-02]],\n",
       "\n",
       "        [[1.27975727e-04]],\n",
       "\n",
       "        [[2.12178156e-02]],\n",
       "\n",
       "        [[3.37234596e-05]],\n",
       "\n",
       "        [[0.00000000e+00]],\n",
       "\n",
       "        [[5.89032075e-04]],\n",
       "\n",
       "        [[5.73100406e-05]],\n",
       "\n",
       "        [[4.18476686e-02]],\n",
       "\n",
       "        [[4.39579785e-02]],\n",
       "\n",
       "        [[3.66692208e-02]],\n",
       "\n",
       "        [[2.23007090e-02]],\n",
       "\n",
       "        [[3.73309031e-02]],\n",
       "\n",
       "        [[4.93711829e-02]],\n",
       "\n",
       "        [[0.00000000e+00]],\n",
       "\n",
       "        [[6.55975964e-05]],\n",
       "\n",
       "        [[1.12915374e-02]],\n",
       "\n",
       "        [[5.99570572e-04]],\n",
       "\n",
       "        [[5.15785143e-02]],\n",
       "\n",
       "        [[6.58715959e-04]],\n",
       "\n",
       "        [[3.75182629e-02]],\n",
       "\n",
       "        [[2.44858358e-02]],\n",
       "\n",
       "        [[0.00000000e+00]],\n",
       "\n",
       "        [[2.92675500e-03]],\n",
       "\n",
       "        [[9.18509439e-03]],\n",
       "\n",
       "        [[2.56514139e-02]],\n",
       "\n",
       "        [[7.30412751e-07]],\n",
       "\n",
       "        [[1.60308919e-05]],\n",
       "\n",
       "        [[3.68853193e-03]]]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now restore old optizer state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer state\n",
    "i = 0\n",
    "for group in cnn.optimizer.state_dict()['param_groups']:\n",
    "    for key in group['params']:\n",
    "        tensor = cnn.optimizer.state_dict()['state'][key]['momentum_buffer']\n",
    "        cnn.optimizer.state_dict()['state'][key]['momentum_buffer'] = torch.Tensor(optimizer_state[i]).to(tensor.device)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check again to see that this time the actual piece of state matches what we had saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'momentum_buffer': tensor([[[[1.0154e-02]],\n",
       " \n",
       "          [[6.5403e-06]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[2.2961e-02]],\n",
       " \n",
       "          [[2.0056e-02]],\n",
       " \n",
       "          [[1.2798e-04]],\n",
       " \n",
       "          [[2.1218e-02]],\n",
       " \n",
       "          [[3.3723e-05]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[5.8903e-04]],\n",
       " \n",
       "          [[5.7310e-05]],\n",
       " \n",
       "          [[4.1848e-02]],\n",
       " \n",
       "          [[4.3958e-02]],\n",
       " \n",
       "          [[3.6669e-02]],\n",
       " \n",
       "          [[2.2301e-02]],\n",
       " \n",
       "          [[3.7331e-02]],\n",
       " \n",
       "          [[4.9371e-02]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[6.5598e-05]],\n",
       " \n",
       "          [[1.1292e-02]],\n",
       " \n",
       "          [[5.9957e-04]],\n",
       " \n",
       "          [[5.1579e-02]],\n",
       " \n",
       "          [[6.5872e-04]],\n",
       " \n",
       "          [[3.7518e-02]],\n",
       " \n",
       "          [[2.4486e-02]],\n",
       " \n",
       "          [[0.0000e+00]],\n",
       " \n",
       "          [[2.9268e-03]],\n",
       " \n",
       "          [[9.1851e-03]],\n",
       " \n",
       "          [[2.5651e-02]],\n",
       " \n",
       "          [[7.3041e-07]],\n",
       " \n",
       "          [[1.6031e-05]],\n",
       " \n",
       "          [[3.6885e-03]]]], device='cuda:0')}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.optimizer.state_dict()['state'][optimizer_keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.5859056,\n",
       " 'Sum of batch is data: [[[-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  ...\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]]], target: [[[0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]]]')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now train to get a new validation\n",
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03464584346511401"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now restore model and optimizer to see that training results in the same validation after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.set_tensor_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set optimizer state\n",
    "i = 0\n",
    "for group in cnn.optimizer.state_dict()['param_groups']:\n",
    "    for key in group['params']:\n",
    "        tensor = cnn.optimizer.state_dict()['state'][key]['momentum_buffer']\n",
    "        cnn.optimizer.state_dict()['state'][key]['momentum_buffer'] = torch.Tensor(optimizer_state[i]).to(tensor.device)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034646598491235636"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see that validation has changed back to restored moedl validation\n",
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.5859056,\n",
       " 'Sum of batch is data: [[[-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  ...\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]\\n  [-50.2968 -50.2968 -50.2968 ... -50.2968 -50.2968 -50.2968]]], target: [[[0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  ...\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]\\n  [0. 0. 0. ... 0. 0. 0.]]]')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03464584346511401"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### MOVING TO REPRODUCIBILITY OVER PROCESSES (SAVING DURING ONE, RESTORING DURING ANOTHER) ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_key_orders(device):\n",
    "    model= PyTorch2DUNet(device)\n",
    "    model.train_epoch()\n",
    "    # print(\"model train loss: {}\".format(model.train_epoch()))\n",
    "    # print(\"model val result: {}\".format(model.validate()))\n",
    "    optimizer_keys = []\n",
    "    for group in model.optimizer.state_dict()['param_groups']:\n",
    "        for key in group['params']:\n",
    "            optimizer_keys.append(key)\n",
    "    # print(\"optimizer_keys: {}\".format(optimizer_keys))\n",
    "    # print(\"state_dict state keys: {}\".format(model.optimizer.state_dict()['state'].keys()))\n",
    "    # print(\"there are {} optimizer keys.\".format(len(optimizer_keys)))\n",
    "    sizes = [model.optimizer.state_dict()['state'][key]['momentum_buffer'].detach().cpu().numpy().shape \n",
    "             for key in optimizer_keys]\n",
    "    # print(\"optimizer info array sizes list:\\n {}\".format(sizes))\n",
    "    \n",
    "    return model, optimizer_keys, sizes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the index 0 shape list the same as the index 0 list? True\n",
      "Is the index 1 shape list the same as the index 0 list? True\n",
      "Is the index 2 shape list the same as the index 0 list? True\n",
      "Is the index 3 shape list the same as the index 0 list? True\n",
      "Is the index 4 shape list the same as the index 0 list? True\n",
      "Is the index 5 shape list the same as the index 0 list? True\n",
      "Is the index 6 shape list the same as the index 0 list? True\n",
      "Is the index 7 shape list the same as the index 0 list? True\n",
      "Is the index 8 shape list the same as the index 0 list? True\n",
      "Is the index 9 shape list the same as the index 0 list? True\n",
      "Is the index 10 shape list the same as the index 0 list? True\n",
      "Is the index 11 shape list the same as the index 0 list? True\n",
      "Is the index 12 shape list the same as the index 0 list? True\n",
      "Is the index 13 shape list the same as the index 0 list? True\n",
      "Is the index 14 shape list the same as the index 0 list? True\n",
      "Is the index 15 shape list the same as the index 0 list? True\n",
      "Is the index 16 shape list the same as the index 0 list? True\n",
      "Is the index 17 shape list the same as the index 0 list? True\n",
      "Is the index 18 shape list the same as the index 0 list? True\n",
      "Is the index 19 shape list the same as the index 0 list? True\n"
     ]
    }
   ],
   "source": [
    "# testing order of shapes is the same for multiple models created in the same process\n",
    "shape_list = None\n",
    "for i in range(20):\n",
    "    _, _, list =  get_optimizer_key_orders(device)\n",
    "    if i==0:\n",
    "        shape_list = list\n",
    "    print(\"Is the index {} shape list the same as the index 0 list? {}\".format(i, list==shape_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving order to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('brandons_shape_list.pkl', 'wb') as file:\n",
    "    pickle.dump(shape_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brandons_shape_list.pkl', 'rb') as file:\n",
    "    restored_shape_list = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_shape_list == shape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### restarting kernel here \n",
    "#### running all begining cells and the cell defining get_optimizer_key_orders ###########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the index 0 shape list the same as the list from last process? True\n",
      "Is the index 1 shape list the same as the list from last process? True\n",
      "Is the index 2 shape list the same as the list from last process? True\n",
      "Is the index 3 shape list the same as the list from last process? True\n",
      "Is the index 4 shape list the same as the list from last process? True\n",
      "Is the index 5 shape list the same as the list from last process? True\n",
      "Is the index 6 shape list the same as the list from last process? True\n",
      "Is the index 7 shape list the same as the list from last process? True\n",
      "Is the index 8 shape list the same as the list from last process? True\n",
      "Is the index 9 shape list the same as the list from last process? True\n"
     ]
    }
   ],
   "source": [
    "# pulling prvious process' shape list from disk\n",
    "with open('brandons_shape_list.pkl', 'rb') as file:\n",
    "    shape_list = pickle.load(file)\n",
    "for i in range(10):\n",
    "    _, _, list =  get_optimizer_key_orders(device)\n",
    "    print(\"Is the index {} shape list the same as the list from last process? {}\".format(i, list==shape_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now trying by getting the keys directly from the dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_key_orders_from_dict(device):\n",
    "    model= PyTorch2DUNet(device)\n",
    "    model.train_epoch()\n",
    "    # print(\"model train loss: {}\".format(model.train_epoch()))\n",
    "    # print(\"model val result: {}\".format(model.validate()))\n",
    "    optimizer_keys = model.optimizer.state_dict()['state'].keys()\n",
    "    sizes = [model.optimizer.state_dict()['state'][key]['momentum_buffer'].detach().cpu().numpy().shape \n",
    "             for key in optimizer_keys]\n",
    "    # print(\"optimizer info array sizes list:\\n {}\".format(sizes))\n",
    "    \n",
    "    return model, optimizer_keys, sizes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the index 0 shape list the same as the index 0 list? True\n",
      "Is the index 1 shape list the same as the index 0 list? False\n",
      "Is the index 2 shape list the same as the index 0 list? False\n",
      "Is the index 3 shape list the same as the index 0 list? False\n"
     ]
    }
   ],
   "source": [
    "shape_list = None\n",
    "for i in range(4):\n",
    "    _, _, list =  get_optimizer_key_orders_from_dict(device)\n",
    "    if i==0:\n",
    "        shape_list = list\n",
    "    print(\"Is the index {} shape list the same as the index 0 list? {}\".format(i, list==shape_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlearn",
   "language": "python",
   "name": "tfedlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
