{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet_data_pipeline \\\n",
    "  import PyTorch2DUNetDPipe as UnetWithPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet \\\n",
    "  import PyTorch2DUNet as Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfedlrn.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to an available gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetWithPipeline(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = datasets._get_dataset_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see that the path to get the appropriate indexed image \n",
    "# looks good at first glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_train_paths = model.idx_to_train_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directories = os.listdir(os.path.join(dataset_dir, \\\n",
    "                  'BraTS17/MICCAI_BraTS17_Data_Training/HGG'))\n",
    "directories[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the paths below should match the concept of enumerateing all image slices\n",
    "# obtained by grabbing 155 axial slice \n",
    "# images from each directory in the list above\n",
    "idx_to_train_paths[0], idx_to_train_paths[1], idx_to_train_paths[2], \\\n",
    "idx_to_train_paths[154], idx_to_train_paths[155], idx_to_train_paths[310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each brain (155 slices) given by a directory in 'directories' at an index\n",
    "# corresponds to the institution number below at the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataset_dir, 'BraTS17/brain_number_to_institution.pkl') \\\n",
    "          ,'rb') as file:\n",
    "    brain_to_inst = pickle.load(file)\n",
    "    \n",
    "# convert to int and shifting by one to be 0-indexed\n",
    "brain_to_inst = [int(entry)-1 for entry in brain_to_inst]\n",
    "brain_to_inst[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new list (of tuples now) whose first entry remains the\n",
    "# correct insitution for that brain and the second is\n",
    "# the index of the brain at that insitution\n",
    "next_idx = np.zeros(10).astype(np.int32)\n",
    "brain_to_inst_and_idx_offset = []\n",
    "for brain_num, inst_num in enumerate(brain_to_inst):\n",
    "    this_inst = brain_to_inst[brain_num]\n",
    "    this_idx_offset = next_idx[this_inst]\n",
    "    next_idx[this_inst] += 155\n",
    "    brain_to_inst_and_idx_offset.append((this_inst, this_idx_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_to_inst_and_idx_offset[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all images and masks at each institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst0 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst0.npy'), [0,3, 1, 2])\n",
    "msks_inst0 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst0.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst1 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst1.npy'), [0,3, 1, 2])\n",
    "msks_inst1 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst1.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst2 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst2.npy'), [0,3, 1, 2])\n",
    "msks_inst2 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst2.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst3 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst3.npy'), [0,3, 1, 2])\n",
    "msks_inst3 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst3.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst4 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst4.npy'), [0,3, 1, 2])\n",
    "msks_inst4 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst4.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst5 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst5.npy'), [0,3, 1, 2])\n",
    "msks_inst5 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst5.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst6 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst6.npy'), [0,3, 1, 2])\n",
    "msks_inst6 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst6.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst7 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst7.npy'), [0,3, 1, 2])\n",
    "msks_inst7 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst7.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst8 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst8.npy'), [0,3, 1, 2])\n",
    "msks_inst8 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst8.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst9 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst9.npy'), [0,3, 1, 2])\n",
    "msks_inst9 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst9.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_institution = [(imgs_inst0, msks_inst0), \n",
    "                  (imgs_inst1, msks_inst1), \n",
    "                  (imgs_inst2, msks_inst2), \n",
    "                  (imgs_inst3, msks_inst3), \n",
    "                  (imgs_inst4, msks_inst4), \n",
    "                  (imgs_inst5, msks_inst5), \n",
    "                  (imgs_inst6, msks_inst6), \n",
    "                  (imgs_inst7, msks_inst7), \n",
    "                  (imgs_inst8, msks_inst8), \n",
    "                  (imgs_inst9, msks_inst9),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data pipeline fetcher\n",
    "pipeline_fetcher = model.read_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test by randomly selecting an index, then checking using the mapping\n",
    "# above whether or not the corresponding image properly matches the\n",
    "# institutional image already stored as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    max_index = 155 * len(directories) - 1\n",
    "    rand_idx = np.random.randint(0, max_index)\n",
    "    pipeline_img, pipeline_msk = pipeline_fetcher(rand_idx)\n",
    "    brain_num = rand_idx // 155\n",
    "    inst_num, idx_offset = brain_to_inst_and_idx_offset[brain_num]\n",
    "    idx = int(rand_idx % 155) + idx_offset\n",
    "    inst_imgs, inst_msks = by_institution[inst_num]\n",
    "    img, msk = inst_imgs[idx], inst_msks[idx]\n",
    "    imgs_eq = pipeline_img == img\n",
    "    msks_eq = pipeline_msk == msk\n",
    "    answer = np.all(np.array([imgs_eq, msks_eq]))\n",
    "    return rand_idx, answer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bool = []\n",
    "idxs_tested = []\n",
    "for _ in range(20):\n",
    "    this_idx, this_answer = run_test()\n",
    "    idxs_tested.append(this_idx)\n",
    "    all_bool.append(this_answer)    \n",
    "print(\"Indices tested were: {}\".format(idxs_tested))    \n",
    "print(\"The test was a success?: {}\".format(np.all(np.array(all_bool))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mean_train_times, std_train_times, \\\n",
    "  mean_data_load_times, std_data_load_times = \\\n",
    "    model.train_epoch_test_performance(num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_times, mean_data_load_times, std_train_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now compare to model that pulls data from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = Unet(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_two, mean_train_times_two, std_train_times_two, \\\n",
    "  mean_data_load_times_two, std_data_load_times_two = \\\n",
    "    model_two.train_epoch_test_performance(num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_times_two, mean_data_load_times_two, std_train_times_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portion of model training taken up by data loading and processing\n",
    "mean_data_load_times/mean_train_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portion of model_two training taken up by data loading and processing\n",
    "mean_data_load_times_two/mean_train_times_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by what factor does train time expand when using pipeline\n",
    "mean_train_times/mean_train_times_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests on GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetWithPipeline(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x has shape: torch.Size([64, 1, 128, 128])\n",
      "input x has shape: torch.Size([64, 1, 128, 128])\n",
      "input x has shape: torch.Size([64, 1, 128, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.3159833,\n",
       " 42.94891369342804,\n",
       " 0.10941922664642334,\n",
       " 42.72566342353821,\n",
       " 0.11082005500793457)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_epoch_test_performance(num_batches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = Unet(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0242453,\n",
       " 0.197165846824646,\n",
       " 0.006660819053649902,\n",
       " 0.002887129783630371,\n",
       " 0.00030481815338134766)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_two.train_epoch_test_performance(num_batches=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218.0152284263959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using GPU, by what factor does train time expand when using pipeline\n",
    "42.949/0.197\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# SCRAPS BELOW #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlearn_Aug19",
   "language": "python",
   "name": "tfedlearn_aug19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
