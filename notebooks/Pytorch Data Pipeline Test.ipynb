{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet_data_pipeline \\\n",
    "  import PyTorch2DUNetDPipe as UnetWithPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet \\\n",
    "  import PyTorch2DUNet as Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfedlrn.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict to an available gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UnetWithPipeline(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = datasets._get_dataset_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing to see that the path to get the appropriate indexed image \n",
    "# looks good at first glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_train_paths = model.idx_to_train_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brats17_TCIA_401_1', 'Brats17_CBICA_AUN_1', 'Brats17_TCIA_319_1']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directories = os.listdir(os.path.join(dataset_dir, \\\n",
    "                  'BraTS17/MICCAI_BraTS17_Data_Training/HGG'))\n",
    "directories[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_TCIA_401_1',\n",
       " '/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_TCIA_401_1',\n",
       " '/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_TCIA_401_1',\n",
       " '/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_TCIA_401_1',\n",
       " '/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_CBICA_AUN_1',\n",
       " '/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_TCIA_319_1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the paths below should match the concept of enumerateing all image slices\n",
    "# obtained by grabbing 155 axial slice \n",
    "# images from each directory in the list above\n",
    "idx_to_train_paths[0], idx_to_train_paths[1], idx_to_train_paths[2], \\\n",
    "idx_to_train_paths[154], idx_to_train_paths[155], idx_to_train_paths[310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each brain (155 slices) given by a directory in 'directories' at an index\n",
    "# corresponds to the institution number below at the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 7, 2, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(dataset_dir, 'BraTS17/brain_number_to_institution.pkl') \\\n",
    "          ,'rb') as file:\n",
    "    brain_to_inst = pickle.load(file)\n",
    "    \n",
    "# convert to int and shifting by one to be 0-indexed\n",
    "brain_to_inst = [int(entry)-1 for entry in brain_to_inst]\n",
    "brain_to_inst[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new list (of tuples now) whose first entry remains the\n",
    "# correct insitution for that brain and the second is\n",
    "# the index of the brain at that insitution\n",
    "next_idx = np.zeros(10).astype(np.int32)\n",
    "brain_to_inst_and_idx_offset = []\n",
    "for brain_num, inst_num in enumerate(brain_to_inst):\n",
    "    this_inst = brain_to_inst[brain_num]\n",
    "    this_idx_offset = next_idx[this_inst]\n",
    "    next_idx[this_inst] += 155\n",
    "    brain_to_inst_and_idx_offset.append((this_inst, this_idx_offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (0, 0), (7, 0), (2, 0), (1, 155), (8, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_to_inst_and_idx_offset[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all images and masks at each institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst0 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst0.npy'), [0,3, 1, 2])\n",
    "msks_inst0 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst0.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst1 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst1.npy'), [0,3, 1, 2])\n",
    "msks_inst1 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst1.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst2 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst2.npy'), [0,3, 1, 2])\n",
    "msks_inst2 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst2.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst3 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst3.npy'), [0,3, 1, 2])\n",
    "msks_inst3 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst3.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst4 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst4.npy'), [0,3, 1, 2])\n",
    "msks_inst4 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst4.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst5 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst5.npy'), [0,3, 1, 2])\n",
    "msks_inst5 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst5.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst6 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst6.npy'), [0,3, 1, 2])\n",
    "msks_inst6 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst6.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst7 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst7.npy'), [0,3, 1, 2])\n",
    "msks_inst7 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst7.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst8 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst8.npy'), [0,3, 1, 2])\n",
    "msks_inst8 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst8.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst9 = np.transpose(np.load('/raid/datasets/BraTS17/imgs_inst9.npy'), [0,3, 1, 2])\n",
    "msks_inst9 = np.transpose(np.load('/raid/datasets/BraTS17/msks_inst9.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_institution = [(imgs_inst0, msks_inst0), \n",
    "                  (imgs_inst1, msks_inst1), \n",
    "                  (imgs_inst2, msks_inst2), \n",
    "                  (imgs_inst3, msks_inst3), \n",
    "                  (imgs_inst4, msks_inst4), \n",
    "                  (imgs_inst5, msks_inst5), \n",
    "                  (imgs_inst6, msks_inst6), \n",
    "                  (imgs_inst7, msks_inst7), \n",
    "                  (imgs_inst8, msks_inst8), \n",
    "                  (imgs_inst9, msks_inst9),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data pipeline fetcher\n",
    "pipeline_fetcher = model.read_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test by randomly selecting an index, then checking using the mapping\n",
    "# above whether or not the corresponding image properly matches the\n",
    "# institutional image already stored as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test():\n",
    "    max_index = 155 * len(directories) - 1\n",
    "    rand_idx = np.random.randint(0, max_index)\n",
    "    pipeline_img, pipeline_msk = pipeline_fetcher(rand_idx)\n",
    "    brain_num = rand_idx // 155\n",
    "    inst_num, idx_offset = brain_to_inst_and_idx_offset[brain_num]\n",
    "    idx = int(rand_idx % 155) + idx_offset\n",
    "    inst_imgs, inst_msks = by_institution[inst_num]\n",
    "    img, msk = inst_imgs[idx], inst_msks[idx]\n",
    "    imgs_eq = pipeline_img == img\n",
    "    msks_eq = pipeline_msk == msk\n",
    "    answer = np.all(np.array([imgs_eq, msks_eq]))\n",
    "    return rand_idx, answer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices tested were: [5892, 20676, 31711, 10999, 23633, 27474, 8211, 18020, 1768, 30852]\n",
      "The test was a success?: True\n"
     ]
    }
   ],
   "source": [
    "all_bool = []\n",
    "idxs_tested = []\n",
    "for _ in range(10):\n",
    "    this_idx, this_answer = run_test()\n",
    "    idxs_tested.append(this_idx)\n",
    "    all_bool.append(this_answer)    \n",
    "print(\"Indices tested were: {}\".format(idxs_tested))    \n",
    "print(\"The test was a success?: {}\".format(np.all(np.array(all_bool))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input x has shape: torch.Size([64, 1, 128, 128])\n",
      "input x has shape: torch.Size([64, 1, 128, 128])\n",
      "input x has shape: torch.Size([64, 1, 128, 128])\n",
      "input x has shape: torch.Size([64, 1, 128, 128])\n",
      "input x has shape: torch.Size([64, 1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "loss, mean_train_times, std_train_times, \\\n",
    "  mean_data_load_times, std_data_load_times = \\\n",
    "    model.train_epoch_test_performance(num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52.043133199214935, 44.28689420223236, 3.7586319103531824)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train_times, mean_data_load_times, std_train_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now compare to model that pulls data from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = Unet(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_two, mean_train_times_two, std_train_times_two, \\\n",
    "  mean_data_load_times_two, std_data_load_times_two = \\\n",
    "    model_two.train_epoch_test_performance(num_batches=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.532769978046417, 0.005398869514465332, 0.11272035446925488)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train_times_two, mean_data_load_times_two, std_train_times_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8509651798385656"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# portion of model training taken up by data loading and processing\n",
    "mean_data_load_times/mean_train_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007167176921902372"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# portion of model_two training taken up by data loading and processing\n",
    "mean_data_load_times_two/mean_train_times_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.908897172074812"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by what factor does train time expand when using pipeline\n",
    "mean_train_times/mean_train_times_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# SCRAPS BELOW #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_w_pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-099f64308750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipeline_fetcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_w_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpipeline_fetcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeatures_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_in_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_in_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_w_pipe' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "pipeline_fetcher = model_w_pipe.read_train\n",
    "images_in_batch = [pipeline_fetcher(i) for i in range(batch_size)]\n",
    "features_in_batch = [np.expand_dims(features, axis=0) for features, labels in images_in_batch]\n",
    "labels_in_batch = [np.expand_dims(labels, axis=0) for features, labels in images_in_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_in_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_pipe = np.concatenate(features_in_batch, axis=0)\n",
    "batch_labels_pipe = np.concatenate(labels_in_batch, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_pipe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_features_pipe.dtype)\n",
    "print(batch_features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust above to account for our 0 first ordering\n",
    "brain_to_inst = [str(int(inst) - 1) for inst in brain_to_inst]\n",
    "brain_to_inst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how the files show up when walking the directory\n",
    "# as we do in the new_dataset_converter.py\n",
    "root_dir = '/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG'\n",
    "dir_dict = {}\n",
    "counter = 0\n",
    "for subdir, dir, files in os.walk(root_dir):\n",
    "    if subdir == root_dir:\n",
    "        continue\n",
    "    else:\n",
    "        dir_dict[subdir] = counter\n",
    "        print(subdir)\n",
    "    counter += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find when the file we see first (using ls) comes up in the list\n",
    "# I am working off of the assumption that the map of brain to inst uses\n",
    "# the order observed using ls (rather than the walk above)\n",
    "location_of_first = \\\n",
    "  dir_dict['/raid/datasets/BraTS17/MICCAI_BraTS17_Data_Training/HGG/Brats17_2013_10_1']\n",
    "print(\"Our file walk will put the first brain we see at index: {}\".format(location_of_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets grab the first slice of the brain at that index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which insitution holds this ls_first brain\n",
    "# recall we are guessing the brain_to_inst follows ls order\n",
    "institution_focus = brain_to_inst[0]  \n",
    "print(\"The first brain comes from inst: {}\".format(institution_focus))\n",
    "# inst 1 was the answer above (which means imgs_inst1.npy)\n",
    "# we assume for now that the imgs_inst1.npy file was filled with brains\n",
    "# using the ls_first order\n",
    "which_brain_at_nine = 0\n",
    "print(\"The brain given by file Brats17_2013_10_1 is brain number \"\\\n",
    "  \"{} at insitution {}.\".format(which_brain_at_nine, institution_focus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_inst1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test to see if this all adds up\n",
    "np.all(imgs_inst1[0]== batch_features_pipe.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train.shape, imgs_inst1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = [np.all(imgs_train[70] == imgs_inst1[70+155*num]) for num in range(int(len(imgs_inst1)/155))]\n",
    "for thing in gen:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = [np.all(imgs_train[70] == imgs_inst0[70+155*num]) for num in range(int(len(imgs_inst0)/155))]\n",
    "for thing in gen:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = [np.all(imgs_train[70] == imgs_inst2[70+155*num]) for num in range(int(len(imgs_inst2)/155))]\n",
    "for thing in gen:\n",
    "    print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = np.transpose(np.load('/raid/datasets/BraTS17/imgs_train.npy'), [0,3, 1, 2])\n",
    "msks_train = np.transpose(np.load('/raid/datasets/BraTS17/msks_train.npy'), [0,3, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually update channels on features\n",
    "imgs_train = imgs_train[:,2,:,:]\n",
    "imgs_train = np.expand_dims(imgs_train, axis=1)\n",
    "imgs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_features_pipe.numpy()[0].shape, imgs_inst8[8*155].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(batch_features_pipe.numpy()[0] == imgs_inst8[8*155])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually update channels on features\n",
    "first_brain = first_brain[:,2,:,:]\n",
    "first_brain = np.expand_dims(first_brain, axis=1)\n",
    "first_brain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(first_brain[0] == imgs_inst1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_brain[0].shape, imgs_inst1[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(imgs_inst2[0] == batch_features_pipe[0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(batch_features.numpy()==batch_features_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w_pipe.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 71\n",
    "one_img, one_msk = pipeline_fetcher(71)\n",
    "one_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institutional_sets = [imgs_inst0, imgs_inst1, imgs_inst2, imgs_inst3, imgs_inst4, imgs_inst5, imgs_inst6, imgs_inst7, imgs_inst8, imgs_inst9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(target_img, slice_num, institutional_sets):\n",
    "    slice_num = slice_num % 155\n",
    "    for idx, inst_imgs in enumerate(institutional_sets):\n",
    "        if target_img.shape != inst_imgs[idx].shape:\n",
    "            print(\"Shapes are: {} and {}.\".format(target_img.shape, inst_imgs[idx].shape))\n",
    "            raise ValueError(\"Shapes do not match for at least one insitution!!\")\n",
    "        gen = [(num, np.all(target_img == inst_imgs[slice_num+155*num])) \\\n",
    "               for num in range(int(len(inst_imgs)/155))]\n",
    "        for num, answer in gen:\n",
    "            if answer == True:\n",
    "                print(\"Equality at brain_number: {}, inst idx: {}\".\n",
    "                      format(num, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice_num in range(160, 169, 1):\n",
    "    print(\"For slice number: {}\".format(slice_num))\n",
    "    target_img, target_msk = pipeline_fetcher(slice_num)\n",
    "    compare(target_img, slice_num, institutional_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for slice_num in range(369, 379, 1):\n",
    "    batch_wanted = slice_num // batch_size\n",
    "    idx_within_batch = slice_num % batch_size\n",
    "    for batch_num, (target_img, target_label) in enumerate(model.train_loader):\n",
    "        if batch_num == batch_wanted:\n",
    "            img = target_img[idx_within_batch]\n",
    "            break\n",
    "    print(\"For slice number: {}\".format(slice_num))\n",
    "    compare(img.numpy(), slice_num, institutional_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_features_pipe.shape, imgs_inst1[0:64].shape)\n",
    "np.all(batch_features_pipe == imgs_inst1[0:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(one_img, 70, institutional_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(one_img, 50, institutional_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 60, 1):\n",
    "    print(i)\n",
    "    compare(one_img, i, institutional_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = [(num, np.all(one_img == imgs_inst1[70+155*num])) for num in range(int(len(imgs_inst1)/155))]\n",
    "for num, thing in gen:\n",
    "    if thing == True:\n",
    "        print(\"We got equality at a num of: {}\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = [(num, np.all(one_img == imgs_inst2[70+155*num])) for num in range(int(len(imgs_inst2)/155))]\n",
    "for num, thing in gen:\n",
    "    if thing == True:\n",
    "        print(\"We got equality at a num of: {}\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = [(num, np.all(one_img == imgs_inst3[70+155*num])) for num in range(int(len(imgs_inst3)/155))]\n",
    "for num, thing in gen:\n",
    "    if thing == True:\n",
    "        print(\"We got equality at a num of: {}\".format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "def f(x, y):\n",
    "    return np.sin(x) + np.cos(y)\n",
    "\n",
    "x = np.linspace(0, 2 * np.pi, 120)\n",
    "y = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)\n",
    "# ims is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = []\n",
    "for i in range(60):\n",
    "    x += np.pi / 15.\n",
    "    y += np.pi / 20.\n",
    "    im = plt.imshow(f(x, y), animated=True)\n",
    "    ims.append([im])\n",
    "\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "# To save the animation, use e.g.\n",
    "#\n",
    "# ani.save(\"movie.mp4\")\n",
    "#\n",
    "# or\n",
    "#\n",
    "# from matplotlib.animation import FFMpegWriter\n",
    "# writer = FFMpegWriter(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "# ani.save(\"movie.mp4\", writer=writer)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlearn_Aug19",
   "language": "python",
   "name": "tfedlearn_aug19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
