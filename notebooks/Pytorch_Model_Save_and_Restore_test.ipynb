{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes work from Pytorch MNIST and UNet Dev.ipynb and makes training and validation repeatable \n",
    "# in order to test a method for saving and setting optimizer state (momentum, etc.) that remains consistent\n",
    "# even when the restoring is done after restarting the kernel. The train_epoch method also has been reduced to training\n",
    "# over a few batches (not a complete epoch) in order to make testing faster. Testing should be done for Unet\n",
    "# with its many optimizers, and also for MNIST cnn with its one optimizer.\n",
    "# .................. EDIT THIS ................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe this is how we can test later, for now I am rewriting code below with the following changes\n",
    "# No shuffle on train and val\n",
    "# imports rewritten\n",
    "\n",
    "\n",
    "\n",
    "# from tfedlrn.collaborator.pytorchmodels.pytorch2dunet import PyTorch2DUNet\n",
    "# from tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn import PyTorchMNISTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing my own data pipeline initializer in order to enforce reproducibility by\n",
    "# selecting only one batch for training.\n",
    "\n",
    "from tfedlrn.datasets import load_dataset\n",
    "from tfedlrn.collaborator.pytorchmodels.pytorchflutils import pt_create_loader\n",
    "\n",
    "\n",
    "def init_data_pipelines_no_shuffle(model_type):\n",
    "    \n",
    "    batch_size = 64\n",
    "    \n",
    "    if model_type == PyTorchMNISTCNN:\n",
    "        \n",
    "        X_train, y_train, X_val, y_val = load_dataset('mnist')\n",
    "        X_train = X_train.reshape([-1, 1, 28, 28])\n",
    "        X_val = X_val.reshape([-1, 1, 28, 28])\n",
    "        \n",
    "        # Here is the key reason for implementing this myself.\n",
    "        # Reduce to producing only one batch for training.\n",
    "        X_train, y_train = X_train[:batch_size], y_train[:batch_size]\n",
    "\n",
    "        train_loader = pt_create_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = pt_create_loader(X_val, y_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        \n",
    "    elif model_type == PyTorch2DUNet:\n",
    "        \n",
    "        data_by_institution = [load_dataset('BraTS17_institution',\n",
    "                                                institution=i,\n",
    "                                                channels_first=True) for i in range(10)]\n",
    "        data_by_type = zip(*data_by_institution)\n",
    "        data_by_type = [np.concatenate(d) for d in data_by_type]\n",
    "        X_train, y_train, X_val, y_val = data_by_type\n",
    "        \n",
    "        # Here is the key reason for implementing this myself.\n",
    "        # Reduce to producing only one batch for training.\n",
    "        X_train, y_train = X_train[:batch_size], y_train[:batch_size]\n",
    "        \n",
    "        # Also reduce val loader for unet data so as to not take too long for validation\n",
    "        X_val, y_val = X_val[:batch_size], y_val[:batch_size]\n",
    "\n",
    "        train_loader = pt_create_loader(X_train, y_train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = pt_create_loader(X_val, y_val, batch_size=batch_size, shuffle=True)         \n",
    "         \n",
    "    else:\n",
    "        raise ValueError('This model type not supported.')\n",
    "               \n",
    "    return train_loader, val_loader\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tfedlrn.collaborator.pytorchmodels.pytorchmnistcnn import PyTorchMNISTCNN\n",
    "from tfedlrn.collaborator.pytorchmodels.pytorch2dunet import PyTorch2DUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(device, model_type, unet_optimizer_type):\n",
    "    train_loader, val_loader = init_data_pipelines_no_shuffle(model_type)\n",
    "    if model_type == PyTorchMNISTCNN:\n",
    "        cnn = PyTorchMNISTCNN(device=device, train_loader = train_loader, val_loader = val_loader)\n",
    "    else:\n",
    "        cnn = model_type(device=device, train_loader = train_loader, val_loader = val_loader, optimizer=unet_optimizer_type)\n",
    "    # modifying the learning rate to make a more substantial change when training\n",
    "    # only on one batch, so as to detect after such training that the \n",
    "    # model was not restored correctly\n",
    "    big_learning_rate = 1E-1\n",
    "    for group_idx, group in enumerate(cnn.optimizer.__dict__['param_groups']):\n",
    "        cnn.optimizer.__dict__['param_groups'][group_idx]['lr'] = big_learning_rate\n",
    "    cnn.optimizer.__dict__['defaults']['lr'] = big_learning_rate\n",
    "    \n",
    "    # modifying the momentum so as to test SGD with no state needed\n",
    "    no_momentum = True\n",
    "    if no_momentum:\n",
    "        for group_idx, group in enumerate(cnn.optimizer.__dict__['param_groups']):\n",
    "            cnn.optimizer.__dict__['param_groups'][group_idx]['momentum'] = 0.0\n",
    "        cnn.optimizer.__dict__['defaults']['momentum'] = 0.0\n",
    "    \n",
    "    \n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here set what type of model, dataset, and optimizer you want\n",
    "# (for mnist, no optimizer is needed). Testing using the device as\n",
    "# GPU and CPU should be performed, as well as testing with all optimizer\n",
    "# options, including SGD with momentum=0.0 in order to see that no\n",
    "# required state for the optimizer is handled correctly.\n",
    "\n",
    "# model_type = PyTorchMNISTCNN\n",
    "\n",
    "\n",
    "model_type = PyTorch2DUNet\n",
    "\n",
    "\n",
    "unet_optimizer_type = 'SGD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############         EXPLORING SAVING AND RESTORING OPTIMIZER and MODEL          ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = initialize_model(device=device, model_type=model_type, \n",
    "                       unet_optimizer_type=unet_optimizer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training once to populate the momentum buffers\n",
    "# also testing the extent to which validation is reproducible for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5348387"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate() - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# testing restoring model and optimizer, should result in training to the same validation ##\n",
    "############################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0003709124866873026"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_val = cnn.validate()\n",
    "initial_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model_weights = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train for some more, then see that model is different now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005393"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.423956852406263e-06"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure validation has changed significantly now relative to the difference in repeated validation\n",
    "after_train_val = cnn.validate()\n",
    "after_train_val - initial_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model to disk as well as initial_val and after_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filenames = ['saved_model.pkl', 'initial_val.pkl', 'after_train_val.pkl']\n",
    "objects = [model_weights, initial_val, after_train_val]\n",
    "for ob, filename in zip(objects, filenames):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(ob, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\\/ exploration code here \\/---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here exploring how to modify the learning rate using the optimizer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.optimizer.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here that the param_groups contain lr info\n",
    "print(cnn.optimizer.__dict__['param_groups'][0].keys())\n",
    "print(cnn.optimizer.__dict__['param_groups'][0]['lr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here that the defaults also contain lr \n",
    "# info (this is used by us when restoring optimizer state).\n",
    "print(cnn.optimizer.__dict__['param_groups'][0].keys())\n",
    "print(cnn.optimizer.__dict__['param_groups'][0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See here (by exploring first state key only) that lr info does not lie below the 'state' key \n",
    "first_state_key = list(cnn.optimizer.__dict__['state'].keys())[0]\n",
    "cnn.optimizer.__dict__['state'][first_state_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring how np.float and torch.FloatTensor are indeed compatible.\n",
    "# In fact, the tensors below point to the same memory store, though they print differently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([4.00343, 5.00676]).astype(np.float32)\n",
    "tensor = torch.Tensor(array).to(device)\n",
    "print(\"array data,tensor data, and datatype: {}, {}, {}\"\n",
    "      .format(array, tensor, tensor.type()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array([4.00340, 5.00676]).astype(np.float32)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(\"array data,tensor data, and datatype: {}, {}, {}\"\n",
    "      .format(array, tensor, tensor.type()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array += 1.00004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ /\\ exploration code here /\\ ---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore saved model\n",
    "cnn.set_tensor_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see validation is close to previously observed for saved model\n",
    "initial_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if grabbing the full state again, it gives the same thing as we had saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_2 = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_array = np.array([])\n",
    "for key in model_weights:\n",
    "    if key.startswith('__opt_'):\n",
    "        for inner_key in model_weights[key]:\n",
    "            np.append(bool_array, model_weights[key][inner_key] == model_weights_2[key][inner_key])\n",
    "    else:\n",
    "        np.append(bool_array, [np.all(model_weights[key] == model_weights_2[key])])\n",
    "np.all(bool_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train again and see you get back to the place you did before after running 'train_partial_epoch' once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005393"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9103830456733704e-11"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_train_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_train_val - cnn.validate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----now test that restoring can happen across processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######                         !!!!!!!!!!!!!!!!  RESTART KERNEL HERE !!!!!!!!!!!                 #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######         (then run the top cells of this workbook up to device intialization)            ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Then return to this point and run cells below ####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate model and train a bit, then restore model from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = initialize_model(device=device, model_type=model_type, \n",
    "                       unet_optimizer_type=unet_optimizer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005255"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model weights and validation values from disk BUT NOT RESTORING YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['saved_model.pkl', 'initial_val.pkl', 'after_train_val.pkl']\n",
    "object_names = ['model_weights', 'initial_val', 'after_train_val']\n",
    "for object_name, filename in zip(object_names, filenames):\n",
    "    with open(filename, 'rb') as file:\n",
    "        vars()[object_name] = pickle.load(file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.514906322583556e-06, -9.094947017729282e-08)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if valiation is significantly different from the ones before\n",
    "this_val = cnn.validate()\n",
    "initial_val - this_val,  after_train_val - this_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore model to saved values\n",
    "cnn.set_tensor_dict(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9103830456733704e-11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see validation is close to previously observed for saved model\n",
    "initial_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if grabbing the full state again, it gives the same thing as we had saved before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_2 = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_array = np.array([])\n",
    "for key in model_weights:\n",
    "    if key.startswith('__opt_'):\n",
    "        for inner_key in model_weights[key]:\n",
    "            np.append(bool_array, model_weights[key][inner_key] == model_weights_2[key][inner_key])\n",
    "    else:\n",
    "        np.append(bool_array, [np.all(model_weights[key] == model_weights_2[key])])\n",
    "np.all(bool_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5005393"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now train to get a new validation, and see that it matches what we had after training once before\n",
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9103830456733704e-11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "after_train_val - cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlearn",
   "language": "python",
   "name": "tfedlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
