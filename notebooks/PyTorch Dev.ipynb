{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import socket\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def _get_dataset_func_map():\n",
    "    return {\n",
    "        'mnist': load_mnist,\n",
    "#         'fashion-mnist': load_fashion_mnist,\n",
    "#         'pubfig83': load_pubfig83,\n",
    "#         'cifar10': load_cifar10,\n",
    "#         'cifar20': load_cifar20,\n",
    "#         'cifar100': load_cifar100,\n",
    "#         'bsm': load_bsm,\n",
    "#         'BraTS17': load_BraTS17,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_dataset_list():\n",
    "    return list(_get_dataset_func_map().keys())\n",
    "\n",
    "\n",
    "def load_dataset(dataset, **kwargs):\n",
    "    if dataset not in get_dataset_list():\n",
    "        raise ValueError(\"Dataset {} not in list of datasets {get_dataset_list()}\".format(dataset))\n",
    "    return _get_dataset_func_map()[dataset](**kwargs)\n",
    "\n",
    "\n",
    "def _get_dataset_dir(server=None):\n",
    "    if server is None:\n",
    "        server = socket.gethostname()\n",
    "    server_to_path = {'spr-gpu01': os.path.join('/', 'raid', 'datasets'),\n",
    "                      'edwardsb-Z270X-UD5': os.path.join('/', 'data'),\n",
    "                      'msheller-ubuntu': os.path.join('/', 'home', 'msheller', 'datasets')}\n",
    "    return server_to_path[server]\n",
    "\n",
    "\n",
    "def _unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        d = pickle.load(fo, encoding='bytes')\n",
    "    return d\n",
    "\n",
    "\n",
    "def _read_mnist(path, **kwargs):\n",
    "    X_train, y_train = _read_mnist_kind(path, kind='train', **kwargs)\n",
    "    X_test, y_test = _read_mnist_kind(path, kind='t10k', **kwargs)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# from https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "def _read_mnist_kind(path, kind='train', one_hot=True, **kwargs):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    images = images.astype(float) / 255\n",
    "    if one_hot:\n",
    "        labels = _one_hot(labels.astype(np.int), 10)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_mnist(**kwargs):\n",
    "    path = os.path.join(_get_dataset_dir(), 'mnist', 'input_data')\n",
    "    return _read_mnist(path, **kwargs)\n",
    "\n",
    "\n",
    "def load_fashion_mnist(**kwargs):\n",
    "    path = os.path.join(_get_dataset_dir(), 'fashion-mnist')\n",
    "    return _read_mnist(path, **kwargs)\n",
    "\n",
    "\n",
    "def _one_hot(y, n):\n",
    "    return np.eye(n)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class FLModel(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_tensor_dict(self):\n",
    "        \"\"\"Returns all parameters for aggregation, including optimizer parameters, if appropriate\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def set_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"Returns all parameters for aggregation, including optimizer parameters, if appropriate\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def train_epoch(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_training_data_size(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def validate(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_validation_data_size(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PyTorchFLModel(FLModel, nn.Module):\n",
    "    \"\"\"WIP code. Goal is to simplify porting a model to this framework.\n",
    "    Currently, this creates a placeholder and assign op for every variable, which grows the graph considerably.\n",
    "    Also, the abstraction for the tf.session isn't ideal yet.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # calls nn.Module init\n",
    "        super(PyTorchFLModel, self).__init__()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_optimizer(self):\n",
    "        pass\n",
    "\n",
    "    def get_optimizer_tensors(self):\n",
    "        optimizer = self.get_optimizer()\n",
    "\n",
    "        tensor_dict = {}\n",
    "\n",
    "        # NOTE: this gave inconsistent orderings across collaborators, so does not work\n",
    "        # state = optimizer.state_dict()['state']\n",
    "\n",
    "        # # FIXME: this is really fragile. Need to understand what could change here\n",
    "        # for i, sk in enumerate(state.keys()):\n",
    "        #     if isinstance(state[sk], dict):\n",
    "        #         for k, v in state[sk].items():\n",
    "        #             if isinstance(v, torch.Tensor):\n",
    "        #                 tensor_dict['{}_{}'.format(i, k)] = v.cpu().numpy()\n",
    "\n",
    "        # FIXME: not clear that this works consistently across optimizers\n",
    "        # FIXME: hard-coded naming convention sucks and could absolutely break\n",
    "        i = 0\n",
    "        for group in optimizer.param_groups:\n",
    "            for p in group['params']:\n",
    "                tensor_dict['__opt_{}'.format(i)] = p.detach().cpu().numpy()\n",
    "                i += 1\n",
    "\n",
    "        return tensor_dict\n",
    "                    \n",
    "    def set_optimizer_tensors(self, tensor_dict):\n",
    "        optimizer = self.get_optimizer()\n",
    "\n",
    "        # NOTE: the state dict ordering wasn't consistent. We'd like to use load_state_dict rather than\n",
    "        # directly setting the tensors, if possible, but it's not clear that we can\n",
    "#         state = optimizer.state_dict()\n",
    "\n",
    "#         # FIXME: this is really fragile. Need to understand what could change here\n",
    "#         for i, sk in enumerate(state['state'].keys()):\n",
    "#             if isinstance(state['state'][sk], dict):\n",
    "#                 for k, v in state['state'][sk].items():\n",
    "#                     if isinstance(v, torch.Tensor):\n",
    "#                         key = '{}_{}'.format(i, k)\n",
    "                        \n",
    "#                         if key not in tensor_dict:\n",
    "#                             raise ValueError('{} not in keys: {}'.format(key, list(tensor_dict.keys())))\n",
    "                        \n",
    "#                         state['state'][sk][k] = torch.Tensor(tensor_dict[key]).to(v.device)\n",
    "#         optimizer.load_state_dict(state)\n",
    "        \n",
    "        # FIXME: not clear that this works consistently across optimizers\n",
    "        # FIXME: hard-coded naming convention sucks and could absolutely break\n",
    "        i = 0\n",
    "        for group in optimizer.param_groups:\n",
    "            for idx, p in enumerate(group['params']):\n",
    "                old = group['params'][idx]\n",
    "                new = torch.Tensor(tensor_dict['__opt_{}'.format(i)]).to(old.device)\n",
    "\n",
    "    def get_tensor_dict(self):\n",
    "        # FIXME: should we use self.parameters()??? Unclear if load_state_dict() is better or simple assignment is better\n",
    "        # for now, state dict gives us names, which is good\n",
    "\n",
    "        # FIXME: do both and sanity check each time?\n",
    "\n",
    "        # FIXME: can this have values other than the tensors????\n",
    "        state = self.state_dict()\n",
    "        for k, v in state.items():\n",
    "            state[k] = v.cpu().numpy() # get as a numpy array\n",
    "        return {**state, **self.get_optimizer_tensors()}\n",
    "\n",
    "    def set_tensor_dict(self, tensor_dict):\n",
    "        # FIXME: should we use self.parameters()??? Unclear if load_state_dict() is better or simple assignment is better\n",
    "        # for now, state dict gives us names, which is good\n",
    "        \n",
    "        # FIXME: do both and sanity check each time?\n",
    "\n",
    "        # get the model state so that we can determine the correct tensor values/device placements\n",
    "        model_state = self.state_dict()\n",
    "\n",
    "        new_state = {}\n",
    "        for k, v in model_state.items():\n",
    "            new_state[k] = torch.Tensor(tensor_dict[k]).to(v.device)\n",
    "\n",
    "        # set model state\n",
    "        self.load_state_dict(new_state)\n",
    "\n",
    "        # next we have the optimizer state\n",
    "        self.set_optimizer_tensors(tensor_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PyTorchMNISTCNN(PyTorchFLModel):\n",
    "\n",
    "    def __init__(self, device, train_loader=None, val_loader=None):\n",
    "        super(PyTorchMNISTCNN, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.init_data_pipeline(train_loader, val_loader)\n",
    "        self.init_network(device)\n",
    "        self.init_optimizer()\n",
    "\n",
    "    def create_loader(self, X, y, **kwargs):\n",
    "        tX = torch.stack([torch.Tensor(i) for i in X])\n",
    "        ty = torch.stack([torch.Tensor(i) for i in y])\n",
    "        return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tX, ty), **kwargs)\n",
    "\n",
    "    def init_data_pipeline(self, train_loader, val_loader):\n",
    "        if train_loader is None or val_loader is None:\n",
    "            X_train, y_train, X_val, y_val = load_dataset('mnist')\n",
    "            X_train = X_train.reshape([-1, 1, 28, 28])\n",
    "            X_val = X_val.reshape([-1, 1, 28, 28])\n",
    "\n",
    "        if train_loader is None:\n",
    "            self.train_loader = self.create_loader(X_train, y_train, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            self.train_loader = train_loader\n",
    "\n",
    "        if val_loader is None:\n",
    "            self.val_loader = self.create_loader(X_val, y_val, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            self.val_loader = val_loader\n",
    "\n",
    "    def init_network(self, device):\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set to \"training\" mode\n",
    "        self.train()\n",
    "        \n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device, dtype=torch.int64)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self(data)\n",
    "            loss = F.cross_entropy(output, torch.max(target, 1)[1])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "        return np.mean(losses)\n",
    "\n",
    "    def get_training_data_size(self):\n",
    "        return len(self.train_loader.dataset)\n",
    "\n",
    "    def validate(self):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device, dtype=torch.int64)\n",
    "                output = self(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                target = torch.max(target, 1)[1]\n",
    "                # FIXME: there has to be a better way than exhaustive eq then diagonal\n",
    "                eq = pred.eq(target).diag().sum().cpu().numpy()\n",
    "                correct += eq\n",
    "\n",
    "        return correct / self.get_validation_data_size()\n",
    "\n",
    "    def get_validation_data_size(self):\n",
    "        return len(self.val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = PyTorchMNISTCNN(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 1.67084947e-01,  1.86375901e-01,  1.00053325e-01,\n",
       "           1.64982453e-01,  8.70953053e-02],\n",
       "         [-1.06564015e-02, -4.80252057e-02, -4.84155416e-02,\n",
       "           1.90959230e-01,  1.90107241e-01],\n",
       "         [-1.37146711e-02,  1.83534876e-01,  8.80192965e-02,\n",
       "          -1.94152221e-01,  1.94642380e-01],\n",
       "         [-1.19294643e-01,  1.51802465e-01, -1.63783342e-01,\n",
       "          -1.41910478e-01, -4.71500903e-02],\n",
       "         [-3.84559184e-02, -8.18441659e-02, -1.18468285e-01,\n",
       "           1.45418838e-01, -8.97213221e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 7.37374276e-02, -5.68345189e-03, -1.58699036e-01,\n",
       "           3.09284180e-02,  8.07703286e-02],\n",
       "         [ 3.11407745e-02,  8.91415924e-02, -3.81489247e-02,\n",
       "          -1.61148071e-01, -2.36777812e-02],\n",
       "         [ 7.59230107e-02,  3.57276946e-02, -1.68879271e-01,\n",
       "          -1.63545683e-01,  6.54061288e-02],\n",
       "         [ 2.93422192e-02,  9.74588543e-02, -1.57162547e-01,\n",
       "           5.23739904e-02,  1.92388311e-01],\n",
       "         [ 2.40549147e-02, -1.81072354e-01, -8.38922262e-02,\n",
       "           1.61810532e-01, -4.88879681e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.20682418e-02, -1.94069058e-01,  1.57104269e-01,\n",
       "           1.08866528e-01,  1.81882039e-01],\n",
       "         [ 1.82410911e-01,  1.52718142e-01, -9.27814022e-02,\n",
       "          -1.06166482e-01, -1.97034627e-02],\n",
       "         [-1.12336874e-01, -1.44473553e-01, -1.52253821e-01,\n",
       "          -1.01479247e-01, -1.51527673e-01],\n",
       "         [-1.61187008e-01,  1.82699606e-01,  7.77850598e-02,\n",
       "          -1.68923855e-01,  1.87397256e-01],\n",
       "         [-9.32400227e-02,  7.81948119e-02, -1.92043051e-01,\n",
       "           1.85464397e-01, -1.78064868e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.69359103e-01, -1.39702439e-01, -8.55361968e-02,\n",
       "          -1.95503309e-01, -2.97788382e-02],\n",
       "         [-5.35669327e-02,  4.38614786e-02, -1.23516701e-01,\n",
       "          -1.44662812e-01,  9.93171185e-02],\n",
       "         [-1.18281603e-01,  3.14783603e-02, -7.65310302e-02,\n",
       "          -1.65695280e-01, -1.98493883e-01],\n",
       "         [-1.80223420e-01, -1.09448887e-01,  1.80776566e-02,\n",
       "           1.68380305e-01, -1.09732270e-01],\n",
       "         [ 4.38956320e-02,  7.08332211e-02, -4.12744582e-02,\n",
       "           1.87911108e-01,  1.44974723e-01]]],\n",
       "\n",
       "\n",
       "       [[[-1.76497862e-01,  2.30164826e-03,  3.10610533e-02,\n",
       "          -8.80316496e-02, -5.11435717e-02],\n",
       "         [-3.11602801e-02,  8.67339522e-02,  8.05832595e-02,\n",
       "          -1.46783739e-01, -1.28403515e-01],\n",
       "         [-1.21388726e-01, -7.30032623e-02, -1.14658237e-01,\n",
       "          -2.58795768e-02, -8.56512561e-02],\n",
       "         [ 1.80956498e-01,  1.05221793e-01, -1.33949235e-01,\n",
       "           7.86270648e-02, -1.20226763e-01],\n",
       "         [-1.57488316e-01, -1.98849559e-01,  2.54425108e-02,\n",
       "          -1.35885477e-02, -8.50128904e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.30188718e-01, -1.71920449e-01, -1.32692158e-01,\n",
       "           1.17156804e-02, -8.05418044e-02],\n",
       "         [-4.03968990e-02, -9.42794979e-03, -8.74491706e-02,\n",
       "           9.18734819e-02, -1.17721491e-01],\n",
       "         [-1.10442638e-01,  1.15981296e-01,  4.83763963e-02,\n",
       "           1.48404434e-01,  9.74476337e-03],\n",
       "         [ 1.14996731e-03, -7.29064196e-02, -1.13162972e-01,\n",
       "          -8.54540393e-02,  8.80689174e-02],\n",
       "         [ 7.84211308e-02, -1.93563104e-03, -1.68649867e-01,\n",
       "           8.38478059e-02, -1.84519216e-01]]],\n",
       "\n",
       "\n",
       "       [[[-8.86034966e-02, -5.97116947e-02, -1.39595315e-01,\n",
       "           8.90647918e-02, -1.03505827e-01],\n",
       "         [-7.86535069e-02,  1.03331432e-01,  6.52023405e-02,\n",
       "          -4.08724099e-02,  4.11694795e-02],\n",
       "         [ 9.10515636e-02, -5.93660772e-02,  1.94853202e-01,\n",
       "           1.41091645e-02,  1.86504573e-02],\n",
       "         [ 1.13822684e-01,  6.40283376e-02,  1.39763638e-01,\n",
       "          -6.45840168e-02,  8.23321193e-02],\n",
       "         [-1.47795230e-02, -1.84091434e-01, -6.37166053e-02,\n",
       "           4.47264314e-03,  7.26387650e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 4.14016545e-02, -1.16503075e-01,  3.61716002e-02,\n",
       "           1.04187205e-01, -5.09282351e-02],\n",
       "         [ 1.57663181e-01,  1.43544212e-01, -1.68339103e-01,\n",
       "          -6.60085976e-02, -1.96004733e-01],\n",
       "         [-2.77748853e-02,  1.66498706e-01,  4.75034714e-02,\n",
       "           6.46304339e-02, -1.14761949e-01],\n",
       "         [ 9.25194472e-02, -3.13312709e-02,  6.04593903e-02,\n",
       "           9.34877545e-02, -1.78151950e-01],\n",
       "         [-6.53098375e-02,  1.75300643e-01,  9.50774103e-02,\n",
       "           5.30530661e-02, -1.21198274e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 9.96045768e-03, -1.21748209e-01,  3.59448791e-03,\n",
       "          -2.40757763e-02,  4.54504490e-02],\n",
       "         [ 4.12411988e-03, -8.65975842e-02, -1.16303705e-01,\n",
       "          -1.77291334e-02,  6.02480024e-02],\n",
       "         [-1.66284174e-01,  1.98790237e-01, -8.70216414e-02,\n",
       "          -3.35052460e-02,  1.49671391e-01],\n",
       "         [-1.94470927e-01, -1.50420398e-01, -7.22520798e-02,\n",
       "          -1.12297080e-01,  7.79851228e-02],\n",
       "         [ 8.00085813e-02, -3.72008979e-03, -5.72055578e-02,\n",
       "          -1.94143921e-01,  1.32265091e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.56894401e-01,  9.31101590e-02, -8.98338333e-02,\n",
       "          -1.11656718e-01,  9.79092717e-03],\n",
       "         [ 1.50961474e-01, -5.31547517e-02,  8.97961408e-02,\n",
       "           1.76552996e-01, -1.60647422e-01],\n",
       "         [-8.76095816e-02,  1.15808859e-01, -1.77226886e-01,\n",
       "           5.26665300e-02,  8.36803764e-02],\n",
       "         [ 6.56621307e-02, -1.35896415e-01,  3.94771993e-02,\n",
       "           1.31709114e-01, -5.86547852e-02],\n",
       "         [-1.25510514e-01, -9.39645767e-02,  1.76617697e-01,\n",
       "          -9.18693542e-02,  2.58677304e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.26800999e-01, -1.62100434e-01,  1.35757133e-01,\n",
       "          -1.01295471e-01, -8.46988186e-02],\n",
       "         [-1.30250409e-01,  6.02386743e-02,  4.00765240e-03,\n",
       "          -1.75648481e-02, -1.66989833e-01],\n",
       "         [-1.55274659e-01,  9.72151756e-04, -1.66791037e-01,\n",
       "          -8.76489431e-02, -5.90515584e-02],\n",
       "         [ 1.10833928e-01,  1.25105307e-01,  1.72130004e-01,\n",
       "          -1.67918086e-01, -8.91332328e-03],\n",
       "         [-6.86092079e-02,  1.83054641e-01, -1.96620941e-01,\n",
       "          -1.28780127e-01,  7.48950690e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 1.02571234e-01,  1.40320644e-01, -1.85191423e-01,\n",
       "           1.90437332e-01, -1.36860222e-01],\n",
       "         [ 1.06306151e-01, -1.21057332e-02,  7.90953636e-03,\n",
       "          -7.47664869e-02,  1.50936589e-01],\n",
       "         [ 6.95527941e-02,  2.98118591e-02, -8.82477090e-02,\n",
       "          -1.27116159e-01, -4.41826880e-02],\n",
       "         [-1.88419461e-01,  9.88018364e-02, -5.44460267e-02,\n",
       "           1.36199370e-01, -6.98367357e-02],\n",
       "         [-1.15089871e-01,  1.90921560e-01,  4.52338010e-02,\n",
       "          -1.20767668e-01, -2.12526321e-02]]],\n",
       "\n",
       "\n",
       "       [[[-2.25799084e-02, -1.09960988e-01, -1.84593230e-01,\n",
       "          -4.41227406e-02,  6.79888874e-02],\n",
       "         [-1.69950470e-01,  1.07472494e-01, -7.84924254e-02,\n",
       "          -1.69842988e-01, -1.30627468e-01],\n",
       "         [-5.20005524e-02,  1.99561119e-02, -4.86977100e-02,\n",
       "          -1.24786928e-01,  1.17189512e-01],\n",
       "         [ 6.95758313e-02,  3.35648656e-04, -1.22562699e-01,\n",
       "           2.15196609e-03, -6.83535784e-02],\n",
       "         [-3.15848291e-02,  2.81593353e-02, -5.41753471e-02,\n",
       "           6.92656636e-03, -4.57975119e-02]]],\n",
       "\n",
       "\n",
       "       [[[-3.60859632e-02,  1.85558632e-01, -1.35301530e-01,\n",
       "           5.19208461e-02,  3.96668166e-02],\n",
       "         [ 1.77612826e-01, -3.22608054e-02, -7.43599683e-02,\n",
       "           1.54335037e-01,  1.05425879e-01],\n",
       "         [ 1.69242576e-01,  1.35909185e-01, -1.21901207e-01,\n",
       "          -1.76398084e-01, -1.06747746e-01],\n",
       "         [ 4.97596562e-02,  6.06010705e-02, -1.63394764e-01,\n",
       "          -1.51284620e-01, -1.26564831e-01],\n",
       "         [-5.76885045e-02,  1.78704873e-01, -1.66173309e-01,\n",
       "          -1.80001184e-01,  1.26048103e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 1.00427404e-01, -1.76232308e-02,  1.78624108e-01,\n",
       "           2.59134769e-02, -1.59039184e-01],\n",
       "         [-9.30815935e-04,  6.71552569e-02,  2.89994776e-02,\n",
       "           1.18441135e-02, -8.09346959e-02],\n",
       "         [ 1.03436187e-01, -1.60444051e-01, -4.64607030e-02,\n",
       "          -9.99248996e-02,  1.30502716e-01],\n",
       "         [-3.55151594e-02, -1.98019773e-01,  7.02345520e-02,\n",
       "          -6.51247501e-02,  1.74626485e-01],\n",
       "         [ 1.83564723e-02,  6.40722960e-02,  1.42455921e-01,\n",
       "          -5.48750162e-04, -4.64589596e-02]]],\n",
       "\n",
       "\n",
       "       [[[-1.05954818e-01,  1.49500504e-01, -1.50294185e-01,\n",
       "          -5.91564476e-02, -4.91757691e-02],\n",
       "         [-1.92696244e-01, -1.46446526e-02, -6.84984177e-02,\n",
       "           2.49927342e-02, -1.50816411e-01],\n",
       "         [-1.21798813e-02,  1.95359543e-01, -1.77747726e-01,\n",
       "           1.13081470e-01,  1.39573500e-01],\n",
       "         [-1.16488315e-01, -1.72318891e-01,  1.50222108e-01,\n",
       "           9.00859684e-02,  5.73647469e-02],\n",
       "         [-1.07174709e-01, -1.42262787e-01,  1.65779188e-01,\n",
       "           6.41174465e-02, -1.47100061e-01]]],\n",
       "\n",
       "\n",
       "       [[[-1.42696902e-01,  6.93997592e-02,  1.17365912e-01,\n",
       "           1.70049682e-01,  4.95669246e-03],\n",
       "         [ 4.45688516e-02,  7.29373842e-02,  1.11512616e-01,\n",
       "           7.61864334e-02,  1.60512224e-01],\n",
       "         [-5.31609505e-02,  1.50807038e-01, -6.76201284e-02,\n",
       "          -1.55141741e-01, -6.57288134e-02],\n",
       "         [ 1.74669191e-01,  8.27251524e-02, -1.38103247e-01,\n",
       "           1.46511033e-01,  1.45858273e-01],\n",
       "         [ 6.38837963e-02, -5.50840646e-02, -1.17556050e-01,\n",
       "          -1.98043853e-01, -4.14104015e-02]]],\n",
       "\n",
       "\n",
       "       [[[-5.10012358e-02,  1.57355919e-01, -1.65136978e-01,\n",
       "          -7.30504990e-02, -7.77833983e-02],\n",
       "         [-1.36285305e-01,  1.80058345e-01, -1.95979625e-02,\n",
       "           1.66752532e-01,  1.78717002e-01],\n",
       "         [ 1.47672191e-01,  9.72540677e-03,  5.47507554e-02,\n",
       "          -9.86843631e-02,  1.53260484e-01],\n",
       "         [ 1.49928316e-01, -1.19442642e-02,  1.36998907e-01,\n",
       "          -6.63031340e-02, -1.77661404e-01],\n",
       "         [-5.64420670e-02, -1.03972793e-01,  1.52677789e-01,\n",
       "          -6.86988086e-02, -5.07545024e-02]]],\n",
       "\n",
       "\n",
       "       [[[-4.71732169e-02,  1.43720910e-01, -2.50170678e-02,\n",
       "           1.24104515e-01, -1.44285485e-01],\n",
       "         [ 1.96595326e-01,  1.46879688e-01, -7.34769851e-02,\n",
       "           1.83471337e-01, -1.33281708e-01],\n",
       "         [-1.54926971e-01, -3.80423963e-02,  8.52850825e-02,\n",
       "           1.99656144e-01, -1.70483828e-01],\n",
       "         [-1.31188035e-01,  3.22205275e-02,  3.67578864e-03,\n",
       "           1.35491177e-01, -1.01760939e-01],\n",
       "         [ 1.44246474e-01, -1.30425289e-01, -8.26255977e-03,\n",
       "          -9.39940214e-02,  1.86870769e-01]]],\n",
       "\n",
       "\n",
       "       [[[-8.54355320e-02, -1.38301566e-01,  1.84818104e-01,\n",
       "          -1.27653182e-01, -1.57695010e-01],\n",
       "         [ 4.34416234e-02,  1.58813938e-01,  4.70077246e-02,\n",
       "          -1.30854189e-01,  9.60972160e-02],\n",
       "         [-1.66945904e-01, -1.62627578e-01,  2.49092877e-02,\n",
       "           2.64540911e-02,  1.48530349e-01],\n",
       "         [ 1.63212791e-01, -1.71325237e-01, -6.23466671e-02,\n",
       "          -1.96576118e-04,  1.06517658e-01],\n",
       "         [ 1.20884433e-01,  5.83407283e-03,  1.17469206e-01,\n",
       "          -1.24806911e-02, -1.30433977e-01]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['__opt_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.632828"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have an issue where we don't get any optimizer params until after some training\n",
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__opt_2', '__opt_4', 'fc1.weight', 'conv1.weight', '__opt_1', '__opt_3', '__opt_6', 'conv2.bias', 'fc2.bias', 'fc1.bias', '__opt_7', '__opt_0', 'conv2.weight', 'conv1.bias', '__opt_5', 'fc2.weight'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1415806"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9732"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.set_tensor_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9439"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.union1d(d.keys(), d2.keys())[0]) == len(d.keys()) and \\\n",
    "np.all([np.all(d[k] == d2[k]) for k in d.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average([[1, 2], [3, 4]], weights=[1, 0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlrn-CPfKUQY7",
   "language": "python",
   "name": "tfedlrn-cpfkuqy7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
