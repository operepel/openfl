{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import os\n",
    "import socket\n",
    "\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "def _get_dataset_func_map():\n",
    "    return {\n",
    "        'mnist': load_mnist,\n",
    "#         'fashion-mnist': load_fashion_mnist,\n",
    "#         'pubfig83': load_pubfig83,\n",
    "#         'cifar10': load_cifar10,\n",
    "#         'cifar20': load_cifar20,\n",
    "#         'cifar100': load_cifar100,\n",
    "#         'bsm': load_bsm,\n",
    "#         'BraTS17': load_BraTS17,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_dataset_list():\n",
    "    return list(_get_dataset_func_map().keys())\n",
    "\n",
    "\n",
    "def load_dataset(dataset, **kwargs):\n",
    "    if dataset not in get_dataset_list():\n",
    "        raise ValueError(\"Dataset {} not in list of datasets {get_dataset_list()}\".format(dataset))\n",
    "    return _get_dataset_func_map()[dataset](**kwargs)\n",
    "\n",
    "\n",
    "def _get_dataset_dir(server=None):\n",
    "    if server is None:\n",
    "        server = socket.gethostname()\n",
    "    server_to_path = {'spr-gpu01': os.path.join('/', 'raid', 'datasets'),\n",
    "                      'edwardsb-Z270X-UD5': os.path.join('/', 'data'),\n",
    "                      'msheller-ubuntu': os.path.join('/', 'home', 'msheller', 'datasets')}\n",
    "    return server_to_path[server]\n",
    "\n",
    "\n",
    "def _unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        d = pickle.load(fo, encoding='bytes')\n",
    "    return d\n",
    "\n",
    "\n",
    "def _read_mnist(path, **kwargs):\n",
    "    X_train, y_train = _read_mnist_kind(path, kind='train', **kwargs)\n",
    "    X_test, y_test = _read_mnist_kind(path, kind='t10k', **kwargs)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# from https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "def _read_mnist_kind(path, kind='train', one_hot=True, **kwargs):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    images = images.astype(float) / 255\n",
    "    if one_hot:\n",
    "        labels = _one_hot(labels.astype(np.int), 10)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_mnist(**kwargs):\n",
    "    path = os.path.join(_get_dataset_dir(), 'mnist', 'input_data')\n",
    "    return _read_mnist(path, **kwargs)\n",
    "\n",
    "\n",
    "def load_fashion_mnist(**kwargs):\n",
    "    path = os.path.join(_get_dataset_dir(), 'fashion-mnist')\n",
    "    return _read_mnist(path, **kwargs)\n",
    "\n",
    "\n",
    "def _one_hot(y, n):\n",
    "    return np.eye(n)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class FLModel(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_tensor_dict(self):\n",
    "        \"\"\"Returns all parameters for aggregation, including optimizer parameters, if appropriate\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def set_tensor_dict(self, tensor_dict):\n",
    "        \"\"\"Returns all parameters for aggregation, including optimizer parameters, if appropriate\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def train_epoch(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_training_data_size(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def validate(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_validation_data_size(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PyTorchFLModel(FLModel, nn.Module):\n",
    "    \"\"\"WIP code. Goal is to simplify porting a model to this framework.\n",
    "    Currently, this creates a placeholder and assign op for every variable, which grows the graph considerably.\n",
    "    Also, the abstraction for the tf.session isn't ideal yet.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # calls nn.Module init\n",
    "        super(PyTorchFLModel, self).__init__()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def get_optimizer(self):\n",
    "        pass\n",
    "\n",
    "    def get_optimizer_tensors(self):\n",
    "        optimizer = self.get_optimizer()\n",
    "\n",
    "        tensor_dict = {}\n",
    "\n",
    "        state = optimizer.state_dict()['state']\n",
    "\n",
    "        # FIXME: this is really fragile. Need to understand what could change here\n",
    "        for i, sk in enumerate(state.keys()):\n",
    "            if isinstance(state[sk], dict):\n",
    "                for k, v in state[sk].items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        tensor_dict['{}_{}'.format(i, k)] = v.cpu().numpy()\n",
    "\n",
    "        return tensor_dict\n",
    "                    \n",
    "    def set_optimizer_tensors(self, tensor_dict):\n",
    "        optimizer = self.get_optimizer()\n",
    "\n",
    "        state = optimizer.state_dict()\n",
    "\n",
    "        # FIXME: this is really fragile. Need to understand what could change here\n",
    "        for i, sk in enumerate(state['state'].keys()):\n",
    "            if isinstance(state['state'][sk], dict):\n",
    "                for k, v in state['state'][sk].items():\n",
    "                    if isinstance(v, torch.Tensor):\n",
    "                        key = '{}_{}'.format(i, k)\n",
    "                        \n",
    "                        if key not in tensor_dict:\n",
    "                            raise ValueError('{} not in keys: {}'.format(key, list(tensor_dict.keys())))\n",
    "                        \n",
    "                        state['state'][sk][k] = torch.Tensor(tensor_dict[key]).to(v.device)\n",
    "        optimizer.load_state_dict(state)\n",
    "\n",
    "    def get_tensor_dict(self):\n",
    "        # FIXME: should we use self.parameters()??? Unclear if load_state_dict() is better or simple assignment is better\n",
    "        # for now, state dict gives us names, which is good\n",
    "\n",
    "        # FIXME: do both and sanity check each time?\n",
    "\n",
    "        # FIXME: can this have values other than the tensors????\n",
    "        state = self.state_dict()\n",
    "        for k, v in state.items():\n",
    "            state[k] = v.cpu().numpy() # get as a numpy array\n",
    "        return {**state, **self.get_optimizer_tensors()}\n",
    "\n",
    "    def set_tensor_dict(self, tensor_dict):\n",
    "        # FIXME: should we use self.parameters()??? Unclear if load_state_dict() is better or simple assignment is better\n",
    "        # for now, state dict gives us names, which is good\n",
    "        \n",
    "        # FIXME: do both and sanity check each time?\n",
    "\n",
    "        # get the model state so that we can determine the correct tensor values/device placements\n",
    "        model_state = self.state_dict()\n",
    "\n",
    "        new_state = {}\n",
    "        for k, v in model_state.items():\n",
    "            new_state[k] = torch.Tensor(tensor_dict[k]).to(v.device)\n",
    "\n",
    "        # set model state\n",
    "        self.load_state_dict(new_state)\n",
    "\n",
    "        # next we have the optimizer state\n",
    "        self.set_optimizer_tensors(tensor_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class PyTorchMNISTCNN(PyTorchFLModel):\n",
    "\n",
    "    def __init__(self, device, train_loader=None, val_loader=None):\n",
    "        super(PyTorchMNISTCNN, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.init_data_pipeline(train_loader, val_loader)\n",
    "        self.init_network(device)\n",
    "        self.init_optimizer()\n",
    "\n",
    "    def create_loader(self, X, y, **kwargs):\n",
    "        tX = torch.stack([torch.Tensor(i) for i in X])\n",
    "        ty = torch.stack([torch.Tensor(i) for i in y])\n",
    "        return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tX, ty), **kwargs)\n",
    "\n",
    "    def init_data_pipeline(self, train_loader, val_loader):\n",
    "        if train_loader is None or val_loader is None:\n",
    "            X_train, y_train, X_val, y_val = load_dataset('mnist')\n",
    "            X_train = X_train.reshape([-1, 1, 28, 28])\n",
    "            X_val = X_val.reshape([-1, 1, 28, 28])\n",
    "\n",
    "        if train_loader is None:\n",
    "            self.train_loader = self.create_loader(X_train, y_train, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            self.train_loader = train_loader\n",
    "\n",
    "        if val_loader is None:\n",
    "            self.val_loader = self.create_loader(X_val, y_val, batch_size=64, shuffle=True)\n",
    "        else:\n",
    "            self.val_loader = val_loader\n",
    "\n",
    "    def init_network(self, device):\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return self.optimizer\n",
    "\n",
    "    def train_epoch(self):\n",
    "        # set to \"training\" mode\n",
    "        self.train()\n",
    "        \n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device, dtype=torch.int64)\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self(data)\n",
    "            loss = F.cross_entropy(output, torch.max(target, 1)[1])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.detach().cpu().numpy())\n",
    "            \n",
    "        return np.mean(losses)\n",
    "\n",
    "    def get_training_data_size(self):\n",
    "        return len(self.train_loader.dataset)\n",
    "\n",
    "    def validate(self):\n",
    "        self.eval()\n",
    "        correct = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in self.val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device, dtype=torch.int64)\n",
    "                output = self(data)\n",
    "                pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "                target = torch.max(target, 1)[1]\n",
    "                # FIXME: there has to be a better way than exhaustive eq then diagonal\n",
    "                eq = pred.eq(target).diag().sum().cpu().numpy()\n",
    "                correct += eq\n",
    "\n",
    "        return correct / self.get_validation_data_size()\n",
    "\n",
    "    def get_validation_data_size(self):\n",
    "        return len(self.val_loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = PyTorchMNISTCNN(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7723057"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have an issue where we don't get any optimizer params until after some training\n",
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fc1.weight', 'fc1.bias', 'conv1.bias', 'conv1.weight', 'conv2.bias', '3_momentum_buffer', 'conv2.weight', '2_momentum_buffer', '5_momentum_buffer', '1_momentum_buffer', '0_momentum_buffer', '6_momentum_buffer', 'fc2.bias', '4_momentum_buffer', '7_momentum_buffer', 'fc2.weight'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9435"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15161966"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.set_tensor_dict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9435"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = cnn.get_tensor_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.union1d(d.keys(), d2.keys())[0]) == len(d.keys()) and \\\n",
    "np.all([np.all(d[k] == d2[k]) for k in d.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'a': 1, 'b': 2}\n",
    "b = {'b': 3, 'a': 3}\n",
    "c = {'c': 4}\n",
    "\n",
    "a.keys() == c.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfedlrn-CPfKUQY7",
   "language": "python",
   "name": "tfedlrn-cpfkuqy7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
