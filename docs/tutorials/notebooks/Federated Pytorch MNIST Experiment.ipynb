{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated MNIST Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/pfoley1/fl_venv/lib/python3.6/site-packages (1.6.0)\n",
      "Requirement already satisfied: mnist in /home/pfoley1/fl_venv/lib/python3.6/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /home/pfoley1/fl_venv/lib/python3.6/site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: future in /home/pfoley1/fl_venv/lib/python3.6/site-packages (from torch) (0.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/pfoley1/fl_venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Install dependencies if not already installed\n",
    "!pip install torch mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import fledge.native as fx\n",
    "from fledge.federated import FederatedModel,FederatedDataSet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the required packages, the next step is setting up our fledge workspace. To do this, simply run the `fx.init()` command as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Workspace Directories\n",
      "Creating Workspace Certifications\n",
      "Creating Workspace Templates\n",
      "Successfully installed packages from /home/pfoley1/.local/workspace/requirements.txt.\n",
      "\n",
      "New workspace directory structure:\n",
      "workspace\n",
      "├── plan\n",
      "│   ├── plan.yaml\n",
      "│   ├── cols.yaml\n",
      "│   ├── data.yaml\n",
      "│   ├── plans\n",
      "│   │   └── default\n",
      "│   └── defaults\n",
      "│       ├── collaborator.yaml\n",
      "│       ├── tasks_torch.yaml\n",
      "│       ├── tasks_fast_estimator.yaml\n",
      "│       ├── tasks_keras.yaml\n",
      "│       ├── assigner.yaml\n",
      "│       ├── task_runner.yaml\n",
      "│       ├── tasks_tensorflow.yaml\n",
      "│       ├── network.yaml\n",
      "│       ├── aggregator.yaml\n",
      "│       ├── defaults\n",
      "│       └── data_loader.yaml\n",
      "├── data\n",
      "│   ├── MNIST\n",
      "│   │   ├── processed\n",
      "│   │   └── raw\n",
      "│   ├── cifar-10-batches-py\n",
      "│   │   ├── data_batch_1\n",
      "│   │   ├── test_batch\n",
      "│   │   ├── data_batch_3\n",
      "│   │   ├── batches.meta\n",
      "│   │   ├── data_batch_2\n",
      "│   │   ├── data_batch_5\n",
      "│   │   ├── data_batch_4\n",
      "│   │   └── readme.html\n",
      "│   └── cifar-10-python.tar.gz\n",
      "├── save\n",
      "│   ├── last.pbuf\n",
      "│   ├── init.pbuf\n",
      "│   ├── torch_cnn_mnist_last.pbuf\n",
      "│   ├── torch_cnn_mnist_best.pbuf\n",
      "│   ├── torch_cnn_mnist_init.pbuf\n",
      "│   ├── keras_cnn_mnist_best.pbuf\n",
      "│   ├── best.pbuf\n",
      "│   ├── keras_cnn_mnist_last.pbuf\n",
      "│   └── keras_cnn_mnist_init.pbuf\n",
      "├── .workspace\n",
      "├── agg_to_col_two_signed_cert.zip\n",
      "├── agg_to_col_one_signed_cert.zip\n",
      "├── final_model\n",
      "├── cert\n",
      "│   ├── ca\n",
      "│   │   ├── signing-ca.crt\n",
      "│   │   ├── root-ca\n",
      "│   │   ├── signing-ca.csr\n",
      "│   │   ├── signing-ca\n",
      "│   │   ├── root-ca.crt\n",
      "│   │   └── root-ca.csr\n",
      "│   ├── config\n",
      "│   │   ├── server.conf\n",
      "│   │   ├── client.conf\n",
      "│   │   ├── root-ca.conf\n",
      "│   │   └── signing-ca.conf\n",
      "│   ├── cert_chain.crt\n",
      "│   ├── server\n",
      "│   │   ├── agg_none.key\n",
      "│   │   ├── agg_none.csr\n",
      "│   │   └── agg_none.crt\n",
      "│   └── client\n",
      "│       ├── col_two.key\n",
      "│       ├── col_two.csr\n",
      "│       ├── col_one.crt\n",
      "│       ├── col_one.key\n",
      "│       ├── col_two.crt\n",
      "│       └── col_one.csr\n",
      "├── code\n",
      "│   ├── keras_cnn.py\n",
      "│   ├── mnist_utils.py\n",
      "│   ├── tfmnist_inmemory.py\n",
      "│   ├── ptmnist_inmemory.py\n",
      "│   ├── pt_cnn.py\n",
      "│   ├── __init__.py\n",
      "│   └── .pt_cnn.py.swp\n",
      "├── logs\n",
      "└── requirements.txt\n",
      "\n",
      "19 directories, 62 files\n",
      "Setting Up Certificate Authority...\n",
      "\n",
      "1.  Create Root CA\n",
      "1.1 Create Directories\n",
      "1.2 Create Database\n",
      "1.3 Create CA Request\n",
      "1.4 Create CA Certificate\n",
      "2.  Create Signing Certificate\n",
      "2.1 Create Directories\n",
      "2.2 Create Database\n",
      "2.3 Create Signing Certificate CSR\n",
      "2.4 Sign Signing Certificate CSR\n",
      "3   Create Certificate Chain\n",
      "\n",
      "Done.\n",
      "Creating AGGREGATOR certificate key pair with following settings: CN=\u001b[31mnone\u001b[0m, SAN=\u001b[31mDNS:none\u001b[0m\n",
      "  Moving AGGREGATOR certificate key pair to: \u001b[32mcert/server\u001b[0m\n",
      "The CSR Hash for file \u001b[32magg_none.csr\u001b[0m = \u001b[31m 7d8687a03327a96e4e7ac65c1952862bb809a6b775b9b5db95bdf2c8deb63362\n",
      "\u001b[0m\n",
      " Signing AGGREGATOR certificate key pair\n",
      "  Moving AGGREGATOR certificate key pair to: \u001b[32mcert/server\u001b[0m\n",
      "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mone\u001b[0m, SAN=\u001b[31mDNS:one\u001b[0m\n",
      "  Moving COLLABORATOR certificate to: \u001b[32mcert/col_one\u001b[0m\n",
      "The CSR Hash for file \u001b[32mcol_one.csr\u001b[0m = \u001b[31m c6631cb07e10bda52481d3559ddbf2bce7138d4444ed53fe5722a10935357065\n",
      "\u001b[0m\n",
      " Signing COLLABORATOR certificate key pair\n",
      "  Moving COLLABORATOR certificate key pair to: \u001b[32mcert/client\u001b[0m\n",
      "\n",
      "Registering \u001b[32mone\u001b[0m in \u001b[32mplan/cols.yaml\u001b[0m\n",
      "Creating COLLABORATOR certificate key pair with following settings: CN=\u001b[31mtwo\u001b[0m, SAN=\u001b[31mDNS:two\u001b[0m\n",
      "  Moving COLLABORATOR certificate to: \u001b[32mcert/col_two\u001b[0m\n",
      "The CSR Hash for file \u001b[32mcol_two.csr\u001b[0m = \u001b[31m 16b93be1745521410c3e040bd8086e9b28de131560e5a5e7b515e89051df8048\n",
      "\u001b[0m\n",
      " Signing COLLABORATOR certificate key pair\n",
      "  Moving COLLABORATOR certificate key pair to: \u001b[32mcert/client\u001b[0m\n",
      "\n",
      "Registering \u001b[32mtwo\u001b[0m in \u001b[32mplan/cols.yaml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Setup default workspace, logging, etc.\n",
    "fx.init('torch_cnn_mnist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to define our dataset and model to perform federated learning on. The dataset should be composed of a numpy arrayWe start with a simple fully connected model that is trained on the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def one_hot(labels, classes):\n",
    "    return np.eye(classes)[labels]\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "#train_images,train_labels = trainset.train_data, trainset.train_labels\n",
    "train_images,train_labels = trainset.data, np.array(trainset.targets)\n",
    "train_images = torch.from_numpy(np.transpose(train_images, (0,3,1,2))).float()\n",
    "train_labels = one_hot(train_labels,10)\n",
    "\n",
    "validset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "#valid_images,valid_labels = validset.test_data, validset.test_labels\n",
    "valid_images,valid_labels = validset.data, np.array(validset.targets)\n",
    "#valid_images.permute(0,3,1,2)\n",
    "valid_images = torch.from_numpy(np.transpose(valid_images, (0,3,1,2))).float()\n",
    "valid_labels = one_hot(valid_labels,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training and validation images/labels\n",
    "#train_images = mnist.train_images()\n",
    "#train_labels = to_categorical(mnist.train_labels())\n",
    "#valid_images = mnist.test_images()\n",
    "#valid_labels = to_categorical(mnist.test_labels())\n",
    "\n",
    "#def preprocess(images):\n",
    "#    #Normalize\n",
    "#    images = (images / 255) - 0.5\n",
    "#    #Flatten\n",
    "#    images = images.reshape((-1, 784))\n",
    "#    return images\n",
    "\n",
    "# Preprocess the images.\n",
    "#train_images = preprocess(train_images)\n",
    "#valid_images = preprocess(valid_images)\n",
    "\n",
    "feature_shape = train_images.shape[1]\n",
    "classes       = 10\n",
    "\n",
    "fl_data = FederatedDataSet(train_images,train_labels,valid_images,valid_labels,batch_size=32,num_classes=classes)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "    \n",
    "optimizer = lambda x: optim.Adam(x, lr=1e-4)\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    \"\"\"Binary cross-entropy metric\n",
    "    \"\"\"\n",
    "    return F.binary_cross_entropy_with_logits(input=output,target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf\">[17:23:54] </span><span style=\"color: #800000\">WARNING</span>  tried to remove tensor: __opt_state_needed not present in the tensor dict                                                        <a href=\"file:///home/pfoley1/demo_venv/lib/python3.6/site-packages/fledge/utilities/utils.py\"><span style=\"color: #7f7f7f\">utils.py</span></a><span style=\"color: #7f7f7f\">:78</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x7fb0509ceeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Create a federated model using the build model function and dataset\n",
    "fl_model = FederatedModel(build_model=net,optimizer=optimizer,loss_fn=cross_entropy,data_loader=fl_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FederatedModel` object is a wrapper around your Keras, Tensorflow or PyTorch model that makes it compatible with fledge. It provides built in federated training and validation functions that we will see used below. Using it's `setup` function, collaborator models and datasets can be automatically defined for the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Adam' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-67f450b4557a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcollaborator_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfl_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_collaborators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcollaborators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'one'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcollaborator_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'two'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcollaborator_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m#, 'three':collaborator_models[2]}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/demo_venv/lib/python3.6/site-packages/fledge/federated/task/fl_model.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, num_collaborators)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFederatedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_slice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_collaborators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFederatedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_slice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_collaborators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/demo_venv/lib/python3.6/site-packages/fledge/federated/task/fl_model.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFederatedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_opt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_slice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_collaborators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFederatedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_slice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata_slice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_collaborators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/demo_venv/lib/python3.6/site-packages/fledge/federated/task/fl_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, build_model, optimizer, loss_fn, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Adam' object is not callable"
     ]
    }
   ],
   "source": [
    "collaborator_models = fl_model.setup(num_collaborators=2)\n",
    "collaborators = {'one':collaborator_models[0],'two':collaborator_models[1]}#, 'three':collaborator_models[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original MNIST dataset\n",
    "print(f'Original training data size: {len(train_images)}')\n",
    "print(f'Original validation data size: {len(valid_images)}\\n')\n",
    "\n",
    "#Collaborator one's data\n",
    "print(f'Collaborator one\\'s training data size: {len(collaborator_models[0].data_loader.X_train)}')\n",
    "print(f'Collaborator one\\'s validation data size: {len(collaborator_models[0].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator two's data\n",
    "print(f'Collaborator two\\'s training data size: {len(collaborator_models[1].data_loader.X_train)}')\n",
    "print(f'Collaborator two\\'s validation data size: {len(collaborator_models[1].data_loader.X_valid)}\\n')\n",
    "\n",
    "#Collaborator three's data\n",
    "#print(f'Collaborator three\\'s training data size: {len(collaborator_models[2].data_loader.X_train)}')\n",
    "#print(f'Collaborator three\\'s validation data size: {len(collaborator_models[2].data_loader.X_valid)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run experiment, return trained FederatedModel\n",
    "final_fl_model = fx.run_experiment(collaborators,{'rounds_to_train':10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save final model\n",
    "final_fl_model.save('final_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo_venv",
   "language": "python",
   "name": "demo_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
